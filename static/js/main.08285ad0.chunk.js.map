{"version":3,"sources":["modules/environment/nestedFloatMatrixMath.js","modules/environment/AgentObservation.js","modules/environment/State.js","modules/environment/generateInitialState.js","modules/environment/index.js","modules/react-ui-component/ObservationRenderer.js","modules/react-ui-component/BrainExportButton.js","modules/react-ui-component/ScoreHistoryChart.js","modules/react-ui-component/GameRulesDisplay.js","modules/agent-hand-programmed-look-ahead/helper/feeler.js","modules/agent-hand-programmed-look-ahead/LookAhead9x3.js","modules/agent-hand-programmed-look-ahead/helper/generateFeelerPathsXByThree.js","modules/environment/viewportConversions.js","modules/lib-agent-helper/qStateRenderer.js","modules/agent-tabular-sarsa/TabularSARSA.js","modules/agent-deep-q-network-tensor-flow/math/arrayMath.js","modules/agent-deep-q-network-tensor-flow/Agent.js","modules/agent-deep-q-network-tensor-flow/math/random.js","agents.js","GameRunner.js","modules/react-ui-component/StatsDisplay.js","App.js","index.js"],"names":["createMatrix","dimensions","matrix","i","Float32Array","shiftAndTrimMatrix","shiftVector","defaultValue","trimVector","outputMatrix","shiftX","shiftY","fromXLen","length","fromYLen","xLen","yLen","Error","x","fromX","fromXRow","toXRow","y","fromY","matrixToFlatArray","vectorI","vector","xI","yI","AgentObservation","tileTypes","score","this","State","position","isComplete","generateInitialState","size","xi","Array","yi","Math","random","generateRandomTileTypes","config","floor","viewPortSize","viewPortOffset","viewPortPosition","verticalDeltaScore","deltaScorePerAction","tileTypeToDeltaScore","getToBottomDeltaScore","actions","Environment","_state","applyAction","bind","getAgentObservation","getGodObservation","viewportOutputMatrix","actionCode","deltaScoreFromHittingEdge","tileType","ceil","limit","ObservationRenderer","state","gameNumber","previousPositions","nextProps","setState","slice","godObservation","agentTileColors","tileColors","xLength","yLength","color","r","g","b","calculateAgentTileColors","props","agentObservation","godTileColors","inPreviousPosition","calculateGodTileColors","className","map","row","rowIndex","key","tileColor","tileIndex","style","backgroundColor","Component","BrainExportButton","onExportButtonClick","exportData","gameRunner","getCurrentAgentInstance","exportBrain","JSON","stringify","alert","onClick","autoFocus","readOnly","width","height","value","ScoreHistoryChart","chartCanvas","refs","chart","myChart","Chart","type","data","labels","datasets","label","borderColor","borderWidth","lineTension","options","animation","duration","elements","point","radius","scales","yAxes","ticks","min","max","xAxes","display","stats","gameCountToAverageScore","gameCountToScore","Object","keys","mapStatsToChartData","forEach","dataset","update","ref","GameRulesDisplay","environmentConfig","toFixed","oppositeActions","w","a","s","d","actionVectors","getFeelerValue","observation","feelerSteps","step","cost","getActionViaFeelers","feelerPaths","lastAction","paths","blacklistedFirstAction","bestFeeler","feelersWithValues","reduce","bestFeelerSoFar","feeler","getBestFeeler","feelerPath","path","getFeelerValues","filter","indexOf","LookAhead9x3","maxSidewaysMoves","permutator","inputArr","result","permute","arr","m","push","curr","next","splice","concat","leftPaths","rightPaths","Set","join","split","sort","aString","bString","generateFeelerPaths","lastReward","observationMatrix","action","convert9x9to5x3OutputMatrix","randomActionValueElement","actionElements","randomActionElement","rewardElements","ensureElementsExist","document","getElementById","innerHTML","renderActionResponse","actionResponse","len","weights","fixedValue","maxActionValue","wasRandom","renderReward","reward","good","bad","rememberLastAction","stateCount","pow","agent","Agent","observationToInt","viewportState","array","output","arrayOfBinariesToInt","TabularSARSA","_lastAction","actionIndex","decide","lastActionStats","getLastActionStats","settings","renderingEnabled","wasRandomlyChosen","saveToJson","getIndexOfMaxValue","maxValue","maxIndex","v","inputCount","numberOfActions","inputTensorShape","DeepQNetworkTensorFlow","learnFromOARO","assign","discountFactor","explorationProbability","model","tf","add","dense","inputShape","units","activation","compile","optimizer","loss","createModel","numberOfInputs","learnAndActCallCount","connectingObservation","lastOAR","actionWasRandom","actionWeights","actionMatrix","modelPredict","arrayMath","observationArray","observationTensor","predictOnBatch","dataSync","targetDataArray","targetTensor","trainOnBatch","then","trainOnBatchResult","dispose","lastObservation","currentObservation","estimatedFutureReward","estimateNextActionReward","target","targetActionValue","modelTrain","predictedRewardByAction","rewardIfDontExplore","rewardIfExplore","accumulator","currentValue","name","getName","class","description","getDescription","ticksPerInterval","defaultStats","currentScore","lastGameScore","scoreSum","gameCount","actionCount","actionsPerSecond","lastSecondsActionCount","lastFinalScores","averageFinalScore","lastActionScore","totalReward","GameRunner","onRender","onStatusChange","_universalGameNumber","_renderingEnabled","_onRender","_stats","_onStatusChange","_agentObservation","_godObservation","_nextAction","newGame","takeAction","tick","clearStats","setRenderingEnabled","last","setInterval","agentInstance","_agent","_environment","_updateObservations","clearBrain","getAction","shift","totalScoreFinaleScore","acc","val","historyLength","StatsDisplay","speed","ticksPerIntervalWhenNotRendering","autoPlay","App","setupInterval","handleGameRunnerStatusChange","handleSpeedSelectorChange","handleGameRendererRender","handleAgentSelectorChange","handleClearBrainClick","handleManualControlKeyDown","handleManualControlClick","_agents","agents","agentInstances","_settings","statsToDisplay","universalGameNumber","currentAgentIndex","lastStatusRenderTime","lastStatusChartRenderTime","scoreHistoryChartData","_gameRunner","clearStatsAndNewGame","nowMilliseconds","Date","getTime","toLocaleString","self","clearInterval","_intervalReference","newEnableRenderingValue","event","setSpeed","prevProps","prevState","clearCurrentAgentBrain","id","onChange","index","onKeyDown","ReactDOM","render"],"mappings":"yYAMO,SAASA,EAAaC,GAGzB,IAFA,IAAIC,EAAS,GAEJC,EAAI,EAAGA,EAAIF,EAAW,GAAIE,IAC/BD,EAAOC,GAAK,IAAIC,aAAaH,EAAW,IAG5C,OAAOC,EAaJ,SAASG,EAAmBH,EAAQI,EAAaC,EAAcC,EAAYC,GAE9E,IAAIC,GADJJ,EAAc,CAACA,EAAY,GAAKE,EAAW,GAAIF,EAAY,GAAKE,EAAW,KAClD,GACrBG,EAASL,EAAY,GACrBM,EAAWV,EAAOW,OAClBC,EAAWZ,EAAO,GAAGW,OACrBE,EAAOH,EAA2B,EAAhBJ,EAAW,GAC7BQ,EAAOF,EAA2B,EAAhBN,EAAW,GACjC,GAAIC,EAAaI,SAAWE,GAAQN,EAAa,GAAGI,SAAWG,EAC3D,MAAM,IAAIC,MAAM,oDACAF,EAAK,IAAIC,EAAK,YAChBP,EAAaI,OAAO,IAAIJ,EAAa,GAAGI,QAG1D,IAAK,IAAIK,EAAI,EAAGA,EAAIH,EAAMG,IAItB,IAHA,IAAIC,EAAQD,EAAIR,EACZU,EAAWlB,EAAOiB,GAClBE,EAASZ,EAAaS,GACjBI,EAAI,EAAGA,EAAIN,EAAMM,IAAK,CAC3B,IAAIC,EAAQD,EAAIX,EAEZU,EAAOC,GADPH,GAAS,GAAKA,EAAQP,GAAYW,GAAS,GAAKA,EAAQT,EAC5CM,EAASE,EAAIX,GAEbJ,GAuBrB,SAASiB,EAAkBtB,GAO9B,IANA,IAAMa,EAAOb,EAAOW,OACdG,EAAOd,EAAO,GAAGW,OACnBY,EAAU,EAEVC,EAAS,IAAItB,aAAaW,EAAOC,GAE5BW,EAAK,EAAGA,EAAKZ,EAAMY,IACxB,IAAK,IAAIC,EAAK,EAAGA,EAAKZ,EAAMY,IACxBF,EAAOD,GAAWvB,EAAOyB,GAAIC,GAC7BH,IAGR,OAAOC,E,IClFUG,EAOjB,WAAYC,EAAWC,GAAsB,oBAIzCC,KAAKF,UAAYA,EAKjBE,KAAKD,MAAQA,GChBAE,EAOjB,WAAYH,EAAWI,EAAUH,EAAOI,GAAa,oBAIjDH,KAAKF,UAAYA,EAIjBE,KAAKE,SAAWA,EAIhBF,KAAKD,MAAQA,EAIbC,KAAKG,WAAaA,GClBbC,EAAuB,WAChC,OAAO,IAAIH,EAcf,SAAiCI,GAI7B,IAHA,IAAMP,EAAY,GACdf,EAAOsB,EAAK,GACZrB,EAAOqB,EAAK,GACPC,EAAK,EAAGA,EAAKvB,EAAMuB,IAAM,CAC9BR,EAAUQ,GAAM,IAAIC,MAAMvB,GAC1B,IAAK,IAAIwB,EAAK,EAAGA,EAAKH,EAAK,GAAIG,IAE3BV,EAAUQ,GAAIE,GAAMC,KAAKC,SAAW,GAAM,EAAI,EAGtD,OAAOZ,EAxBHa,CAAwBC,EAAOP,MAC/B,CAACI,KAAKI,MAAMD,EAAOP,KAAK,GAAK,GAAI,GACjC,GACA,ICVR,IACaO,EAAS,CAElBP,KAAM,CAAC,GAAI,IAGXS,aAAc,CAAC,EAAG,GAClBC,eAAgB,CAAC,EAAG,GACpBC,iBAAkB,CAAC,EAAG,GAGtBC,mBAA+B,IAC/BC,qBAAsB,IACtBC,qBAAsB,CAAC,GAAI,IAC3BC,sBAAuB,GAIdC,EAAU,CAAC,IAAK,IAAK,IAAK,KAKlBC,E,WACjB,aAAe,oBACXtB,KAAKuB,OAASnB,IAGdJ,KAAKwB,YAAcxB,KAAKwB,YAAYC,KAAKzB,MACzCA,KAAK0B,oBAAsB1B,KAAK0B,oBAAoBD,KAAKzB,MACzDA,KAAK2B,kBAAoB3B,KAAK2B,kBAAkBF,KAAKzB,MAGrDA,KAAK4B,qBAAuB5D,EAAa4C,EAAOE,c,wDAQxCe,GACR,IAAIC,EAA4B,EAChC,OAAQD,GACJ,IAAK,IACG7B,KAAKuB,OAAOrB,SAAS,GAAK,GAC1BF,KAAKuB,OAAOrB,SAAS,KACrBF,KAAKuB,OAAOxB,OAASa,EAAOK,oBAE5Ba,EAA4BlB,EAAOO,qBAAqB,GAE5D,MACJ,IAAK,IACGnB,KAAKuB,OAAOrB,SAAS,GAAK,EAC1BF,KAAKuB,OAAOrB,SAAS,KAErB4B,EAA4BlB,EAAOO,qBAAqB,GAE5D,MACJ,IAAK,IACDnB,KAAKuB,OAAOrB,SAAS,KACrBF,KAAKuB,OAAOxB,MAAQC,KAAKuB,OAAOxB,MAAQa,EAAOK,mBAC/C,MACJ,IAAK,IACGjB,KAAKuB,OAAOrB,SAAS,GAAKU,EAAOP,KAAK,GAAK,EAC3CL,KAAKuB,OAAOrB,SAAS,KAErB4B,EAA4BlB,EAAOO,qBAAqB,GAE5D,MACJ,QACI,MAAM,IAAIlC,MAAM,mBAAqB4C,GAG7C,IAAME,EAAW/B,KAAKuB,OAAOzB,UAAUE,KAAKuB,OAAOrB,SAAS,IAAIF,KAAKuB,OAAOrB,SAAS,IAErFF,KAAKuB,OAAOxB,OACRa,EAAOO,qBAAqBY,GAC5BnB,EAAOM,oBACPY,EAEJ9B,KAAKuB,OAAOpB,WAAaH,KAAKuB,OAAOrB,SAAS,KAAOU,EAAOP,KAAK,GAAK,EAClEL,KAAKuB,OAAOpB,aACZH,KAAKuB,OAAOxB,OAASa,EAAOQ,yB,4CAUhC,IAAM9C,EAAc,CAChBmC,KAAKuB,KAAKhC,KAAKuB,OAAOrB,SAAS,GAAKU,EAAOP,KAAK,GAAK,GACrDI,KAAKuB,KAAKhC,KAAKuB,OAAOrB,SAAS,GAAKU,EAAOP,KAAK,GAAK,GAAKO,EAAOG,eAAe,IAE9EvC,EAAa,CACfiC,KAAKI,OAAOD,EAAOP,KAAK,GAAKO,EAAOE,aAAa,IAAM,GACvDL,KAAKI,OAAOD,EAAOP,KAAK,GAAKO,EAAOE,aAAa,IAAM,IAG3DzC,EAAmB2B,KAAKuB,OAAOzB,UAAWxB,EAAa,EAAGE,EAAYwB,KAAK4B,sBAG3E,IAAMK,EAAQrB,EAAOP,KAAK,GAAK7B,EAAW,GAAKF,EAAY,GAC3D,GAAI2D,EAAQrB,EAAOE,aAAa,GAC5B,IAAK,IAAI5B,EAAI,EAAGA,EAAI0B,EAAOE,aAAa,GAAI5B,IACxC,IAAK,IAAII,EAAI2C,EAAO3C,EAAIsB,EAAOE,aAAa,GAAIxB,IAC5CU,KAAK4B,qBAAqB1C,GAAGI,GAAK,EAK9C,OAAO,IAAIO,EACPG,KAAK4B,qBACL5B,KAAKuB,OAAOxB,S,0CAMhB,OAAOC,KAAKuB,W,KCzHCW,E,YACjB,aAAe,IAAD,8BACV,+CACKC,MAAQ,CACTC,WAAY,EACZC,kBAAmB,IAJb,E,uFAQYC,GACtB,GAAIA,EAAUF,aAAepC,KAAKmC,MAAMC,WAEpCpC,KAAKuC,SAAS,CACVH,WAAYE,EAAUF,WACtBC,kBAAmB,SAEpB,CAEH,IAAMA,EAAoBrC,KAAKmC,MAAME,kBAAkBG,QAIvDH,EAFIC,EAAUG,eAAevC,SAAS,GAAKoC,EAAUG,eAAe3C,UAAUjB,OACxEyD,EAAUG,eAAevC,SAAS,KACJ,EACpCF,KAAKuC,SAAS,CACVF,kBAAmBA,O,+BAM3B,IAAMK,EAkFd,SAAkC5C,EAAWI,GAIzC,IAHA,IAAMyC,EAAa,GACbC,EAAU9C,EAAUjB,OACpBgE,EAAU/C,EAAU,GAAGjB,OACpBK,EAAI,EAAGA,EAAI0D,EAAS1D,IACzB,IAAK,IAAII,EAAI,EAAGA,EAAIuD,EAASvD,IAAK,CAC9B,IAAIwD,EAAQ,CAAEC,EAAG,GAAIC,EAAG,GAAIC,EAAG,IAC3B/D,IAAMgB,EAAS,IAAMZ,IAAMY,EAAS,IAA0B,IAApBJ,EAAUZ,GAAGI,GACvDwD,EAAQ,CAAEC,EAAG,IAAKC,EAAG,IAAKC,EAAG,GACtB/D,IAAMgB,EAAS,IAAMZ,IAAMY,EAAS,GAC3C4C,EAAQ,CAAEC,EAAG,EAAGC,EAAG,IAAKC,EAAG,GACA,IAApBnD,EAAUZ,GAAGI,KACpBwD,EAAQ,CAAEC,EAAG,IAAKC,EAAG,EAAGC,EAAG,IAE1BN,EAAWrD,KACZqD,EAAWrD,GAAK,IAEpBqD,EAAWrD,GAAGJ,GAAK,OAAS4D,EAAMC,EAAI,IAAMD,EAAME,EAAI,IAAMF,EAAMG,EAAI,IAG9E,OAAON,EAtGqBO,CAEpBlD,KAAKmD,MAAMC,iBAAiBtD,UAG5Bc,EAAOI,kBAELqC,EA6Cd,SAAgCvD,EAAWI,EAAUmC,GAIjD,IAHA,IAAMM,EAAa,GACbC,EAAU9C,EAAUjB,OACpBgE,EAAU/C,EAAU,GAAGjB,OACpBK,EAAI,EAAGA,EAAI0D,EAAS1D,IACzB,IAAK,IAAII,EAAI,EAAGA,EAAIuD,EAASvD,IAAK,CAC9B,IACIgE,EAAqBjB,EADJnD,EAAI0D,EAAUtD,GAE/BwD,EAAQ,CAAEC,EAAG,GAAIC,EAAG,GAAIC,EAAG,IAC3B/D,IAAMgB,EAAS,IAAMZ,IAAMY,EAAS,IAA0B,IAApBJ,EAAUZ,GAAGI,GACvDwD,EAAQ,CAAEC,EAAG,IAAKC,EAAG,IAAKC,EAAG,GACtB/D,IAAMgB,EAAS,IAAMZ,IAAMY,EAAS,GAC3C4C,EAAQ,CAAEC,EAAG,EAAGC,EAAG,IAAKC,EAAG,GACpBK,GAA0C,IAApBxD,EAAUZ,GAAGI,GAC1CwD,EAAQ,CAAEC,EAAG,IAAKC,EAAG,IAAKC,EAAG,KACtBK,EACPR,EAAQ,CAAEC,EAAG,EAAGC,EAAG,IAAKC,EAAG,GACA,IAApBnD,EAAUZ,GAAGI,KACpBwD,EAAQ,CAAEC,EAAG,IAAKC,EAAG,EAAGC,EAAG,IAE1BN,EAAWrD,KACZqD,EAAWrD,GAAK,IAEpBqD,EAAWrD,GAAGJ,GAAK,OAAS4D,EAAMC,EAAI,IAAMD,EAAME,EAAI,IAAMF,EAAMG,EAAI,IAI9E,OAAON,EAxEmBY,CAClBvD,KAAKmD,MAAMV,eAAe3C,UAC1BE,KAAKmD,MAAMV,eAAevC,SAC1BF,KAAKmC,MAAME,mBAGf,OAAO,yBAAKmB,UAAU,gCAClB,6BACI,4CACA,2BAAOA,UAAU,+BACb,+BACKd,EAAgBe,KAAI,SAACC,EAAKC,GAAN,OACjB,wBAAIC,IAAKD,GACJD,EAAID,KAAI,SAACI,EAAWC,GAAZ,OACL,wBAAIF,IAAKE,EAAWC,MAAO,CAAEC,gBAAiBH,eAOtE,6BACI,kDACA,2BAAOL,UAAU,6BACb,+BACKH,EAAcI,KAAI,SAACC,EAAKC,GAAN,OACf,wBAAIC,IAAKD,GACJD,EAAID,KAAI,SAACI,EAAWC,GAAZ,OACL,wBAAIF,IAAKE,EAAWC,MAAO,CAAEC,gBAAiBH,oB,GAjEjCI,a,ICD5BC,E,YACjB,aAAe,IAAD,8BACV,+CACKC,oBAAsB,EAAKA,oBAAoB1C,KAAzB,gBAC3B,EAAKU,MAAQ,CAACiC,WAAY,MAHhB,E,mFAOV,IAAMC,EAAarE,KAAKmD,MAAMkB,WACzBA,EAAWC,0BAA0BC,YAK1CvE,KAAKuC,SAAS,CACV6B,WAAY,mCACZI,KAAKC,UAAUJ,EAAWC,0BAA0BC,eACpD,QAPAG,MAAM,kD,+BAYV,OACI,6BACI,4BAAQC,QAAS3E,KAAKmE,qBAAtB,sBACCnE,KAAKmC,MAAMiC,YACZ,6BACI,6BACA,2DACA,8BACIQ,WAAS,EACTC,UAAQ,EACRd,MAAO,CAACe,MAAO,OAAQC,OAAQ,QAC/BC,MAAOhF,KAAKmC,MAAMiC,mB,GAjCKH,a,iBCG1BgB,E,4LAEb,IAAIC,EAAclF,KAAKmF,KAAKC,MAExBC,EAAU,IAAIC,IAAMJ,EAAa,CACjCK,KAAM,OACNC,KAAM,CACFC,OAAQ,GACRC,SAAU,CACN,CACIC,MAAO,sBACPH,KAAM,GACNxB,gBAAiB,cACjB4B,YAAa,OACbC,YAAa,EACbC,YAAa,GAEjB,CACIH,MAAO,cACPH,KAAM,GACNxB,gBAAiB,cACjB4B,YAAa,YACbC,YAAa,EACbC,YAAa,KAIzBC,QAAS,CACLC,UAAW,CACPC,SAAU,GAEdC,SAAU,CAACC,MAAO,CAACC,OAAQ,IAC3BC,OAAQ,CACJC,MAAO,CAAC,CACJC,MAAO,CACHC,KAAM,EACNC,IAAK,KAGbC,MAAO,CAAC,CACJC,SAAS,QAMzB3G,KAAKuC,SAAS,CAAC6C,MAAOC,M,0CAGNuB,GAChB,MAAO,CACHlB,SAAU,CACN,CACIF,KAAMoB,EAAMC,wBAAwBrE,OAvDjC,MAyDP,CACIgD,KAAMoB,EAAME,iBAAiBtE,OA1D1B,OA6DXiD,OAAQsB,OAAOC,KAAKJ,EAAME,kBAAkBtE,OA7DjC,Q,2CAkEf,IAAM4C,EAAQpF,KAAKmC,MAAMiD,MACnBI,EAAOxF,KAAKiH,oBAAoBjH,KAAKmD,MAAMyD,OAEjDpB,EAAKE,SAASwB,SAAQ,SAACC,EAAShJ,GAAV,OAAgBiH,EAAMI,KAAKE,SAASvH,GAAGqH,KAAO2B,EAAQ3B,QAE5EJ,EAAMI,KAAKC,OAASD,EAAKC,OACzBL,EAAMgC,W,+BAKN,OACI,4BAAQC,IAAK,QAAStC,OAAQ,MAAOD,MAAO,Y,GA5ETb,aCH1BqD,E,iLAEb,IAAMC,EAAoBvH,KAAKmD,MAAMoE,kBACrC,OACI,2CAEI,4BACI,wEACA,oCAAUA,EAAkBnG,sBAAsBoG,QAAQ,GAA1D,qCACA,sCAAYD,EAAkBpG,qBAAqB,IAAIqG,QAAQ,GAA/D,yCAC2C,IAA1CD,EAAkBrG,qBACf,sCAAYqG,EAAkBrG,qBAAqBsG,QAAQ,GAA3D,0BAEsC,IAAzCD,EAAkBtG,oBACf,oCAAUsG,EAAkBtG,mBAAmBuG,QAAQ,GAAvD,sCAEsC,IAAzCD,EAAkBtG,oBACf,oCAAUsG,EAAkBtG,mBAAmBuG,QAAQ,GAAvD,6C,GAjBsBvD,aCDjCwD,EAAkB,CAC3BC,EAAG,IACHC,EAAG,IACHC,EAAG,IACHC,EAAG,KAGDC,EAAgB,CAElBJ,EAAG,CAAC,GAAI,EAAG9G,EAAOM,oBAAsBN,EAAOK,oBAC/C0G,EAAG,EAAE,EAAG,EAAG/G,EAAOM,qBAClB0G,EAAG,CAAC,EAAG,EAAGhH,EAAOM,oBAAsBN,EAAOK,oBAC9C4G,EAAG,CAAC,EAAG,EAAGjH,EAAOM,sBAEd,SAAS6G,EAAeC,EAAaC,GAExC,IAAI/H,EAAWU,EAAOI,iBAClBgE,EAAQ,EAYZ,OAXAiD,EAAYf,SAAQ,SAACgB,GACjB,IAEIC,EAFEzI,EAASoI,EAAcI,GAC7BhI,EAAW,CAACA,EAAS,GAAKR,EAAO,GAAIQ,EAAS,GAAKR,EAAO,IAGtDyI,EADoC,qBAA7BH,EAAY9H,EAAS,KAAwE,qBAA1C8H,EAAY9H,EAAS,IAAIA,EAAS,IACrFU,EAAOO,qBAAqB,GAE5BP,EAAOO,qBAAqB6G,EAAY9H,EAAS,IAAIA,EAAS,KAEzE8E,EAAQA,EAAQtF,EAAO,GAAKyI,KAEzBnD,EA0BJ,SAASoD,EAAoBJ,EAAaK,EAAaC,GAE1D,IAhBuCC,EAAOC,EAsBxCC,EAlBH,SAAuBC,GAC1B,OAAOA,EAAkBC,QAAO,SAACC,EAAiBC,GAC9C,OAAwB,OAApBD,GAA4BC,EAAO7D,MAAQ4D,EAAgB5D,MACpD6D,EAEAD,IAEZ,MAWgBE,CA/BhB,SAAyBd,EAAaK,GACzC,OAAOA,EAAY5E,KAAI,SAACsF,GACpB,MAAO,CACHC,KAAMD,EACN/D,MAAO+C,EAAeC,EAAae,OAyBjBE,CAAgBjB,GApBHO,EAiBnCF,EAjB0CG,EAiB7Bf,EAAgBa,GAhB1BC,EAAMW,QAAO,SAACF,GAAD,OAAUA,EAAK,KAAOR,QAuB1C,OAAOnH,EAAQ8H,QAAQV,EAAWO,KAAK,I,gBCjEtBI,E,WACjB,aAAe,oBACXpJ,KAAKuB,OAAS,CAAE+G,WAAY,MAC5BtI,KAAKqI,YCLE,SAA6BgB,GAqBxC,IApBA,IAAMC,EAAa,SAACC,GAChB,IAAIC,EAAS,GAab,OAZgB,SAAVC,EAAWC,GAAiB,IAAZC,EAAW,uDAAP,GACtB,GAAmB,IAAfD,EAAI7K,OACJ2K,EAAOI,KAAKD,QAEZ,IAAK,IAAIxL,EAAI,EAAGA,EAAIuL,EAAI7K,OAAQV,IAAK,CACjC,IAAI0L,EAAOH,EAAIlH,QACXsH,EAAOD,EAAKE,OAAO5L,EAAG,GAC1BsL,EAAQI,EAAKrH,QAASmH,EAAEK,OAAOF,KAI3CL,CAAQF,GACDC,GAGPnB,EAAc,CAAC,CAAC,IAAK,MACrB4B,EAAY,CAAC,IAAK,KAClBC,EAAa,CAAC,IAAK,KACd/L,EAAI,EAAGA,EAAIkL,EAAkBlL,IAClC8L,EAAUL,KAAK,KACfM,EAAWN,KAAK,KAChBvB,EAAcA,EAAY2B,OAAOV,EAAWW,GAAYX,EAAWY,IAiBvE,OARA7B,GAFAA,GAHAA,EAAc,YAAI,IAAI8B,IAAI9B,EAAY5E,KAAI,SAAAuF,GAAI,OAAIA,EAAKoB,KAAK,UAAQ3G,KAAI,SAAAuF,GAAI,OAAIA,EAAKqB,MAAM,SAGjEnB,QAAO,SAAAF,GAAI,MAA8B,MAA1BA,EAAKA,EAAKnK,OAAS,OAElCyL,MAAK,SAAC3C,EAAG1E,GAC/B,IAAMsH,EAAU5C,EAAEyC,OACZI,EAAUvH,EAAEmH,OAClB,OAAIG,EAAUC,GAAmB,EAC7BD,EAAUC,EAAkB,EACzB,KDjCYC,CAAoB,G,sDAOjCnC,EAAYoC,EAAYC,GAC9B,IAAIC,EAASxC,EAAoBuC,EAAmB3K,KAAKqI,YAAarI,KAAKuB,OAAO+G,YAIlF,OAFAtI,KAAKuB,OAAO+G,WAAasC,EAElBA,I,qEARP,MAAO,sD,KEHmB5M,EAAa,CAAC,EAAG,IAMjBA,EAAa,CAAC,EAAG,IAMnD,IAAI6M,EAA8B7M,EAAa,CAAC,EAAG,I,ICf/C8M,E,QAHAC,EAAiB,KACjBC,EAAsB,KACtBC,EAAiB,KAIrB,SAASC,IACDC,SAASC,eAAe,cAAmC,OAAnBL,IAG5CI,SAASC,eAAe,0BAA0BC,UAAlD,mrCAcAN,EAAiB,CACbI,SAASC,eAAe,WACxBD,SAASC,eAAe,WACxBD,SAASC,eAAe,WACxBD,SAASC,eAAe,YAE5BJ,EAAsBG,SAASC,eAAe,gBAC9CN,EAA2BK,SAASC,eAAe,qBACnDH,EAAiB,CACbE,SAASC,eAAe,QACxBD,SAASC,eAAe,SAIzB,SAASE,EAAqBC,GACjCL,IAKA,IAJA,IAIS/M,EAAI,EAAGqN,EAAMD,EAAeE,QAAQ5M,OAAQV,EAAIqN,EAAKrN,IAAK,CAC/D,IAAIuN,EAAcH,EAAeE,QAAQtN,KAFtB,EAGfuN,GAHe,EAIfA,EAAa,EACNA,EAAaC,IACpBD,EAAaC,GAEjBD,GAAc,EACdX,EAAe5M,GAAG4F,MAAMe,MAAsB,IAAb4G,EAZb,IAYmD,KACvEX,EAAe5M,GAAGkN,UAAaE,EAAeE,QAAQtN,GAAIqJ,QAAQ,GAGlE+D,EAAeK,WACfd,EAAyBO,UAAY,WACrCL,EAAoBjH,MAAMe,MAAS,UAEnCgG,EAAyBO,UAAY,IACrCL,EAAoBjH,MAAMe,MAAQ,QAInC,SAAS+G,EAAaC,GACzBZ,IAEA,IAAIa,EAAO,EACPC,EAAM,EACNF,EAAS,EACTE,GAAOF,EAEPC,EAAOD,EAGXb,EAAe,GAAGlH,MAAMe,MAAsB,KAAZiH,EAAO,GAAW,IAAO,KAC3Dd,EAAe,GAAGI,UAAYU,EAAKvE,QAAQ,GAE3CyD,EAAe,GAAGlH,MAAMe,MAAqB,KAAXkH,EAAM,GAAW,IAAO,KAC1Df,EAAe,GAAGI,UAAYW,EAAIxE,QAAQ,GClE9C,IAAMyE,GAAqB,EAGdC,EAAazL,KAAK0L,IAAI,EADR,KACkCF,EAAqB5K,EAAQxC,OAAS,GAE/FuN,EAAQ,IAAIC,QAAMH,EAAY7K,EAAQxC,QAwB1C,SAASyN,EAAiBtE,EAAaM,GACnC,IAAIiE,EAhBD,SAA8BC,GAEjC,IADA,IAAIC,EAAS,EACJtO,EAAI,EAAGqN,EAAMgB,EAAM3N,OAAQV,EAAIqN,EAAKrN,IACzCsO,GAAUD,EAAMrO,GAAKsC,KAAK0L,IAAI,EAAGhO,GAErC,OAAOsO,EAWaC,CAChBlN,GFzBJnB,EE4BY2J,EF5Be,CAAC,GAAI,GAAI,EAAG,CAAC,EAAG,GAAI6C,GACxCA,KE+BP,OAAIoB,EACOM,GAAiBjE,EAAa,GAE9BiE,E,IAKMI,E,WACjB,aAAe,oBACX3M,KAAK4M,YAAc,E,sDAoBbtE,EAAYoC,EAAYC,GAE9B,IAAIxI,EAAQmK,EAAiB3B,EAAmB3K,KAAK4M,aACjDC,EAAcT,EAAMU,OAAOpC,EAAYvI,GACvC4K,EAAkBX,EAAMY,qBAW5B,OAVIC,GAASC,mBACT5B,EACI,CACIG,QAASsB,EAAgBtB,QACzBG,UAAWmB,EAAgBI,oBAGnCtB,EAAanB,IAEjB1K,KAAK4M,YAAcC,EACZA,I,sEAMPT,EAAQ,IAAIC,QAAMH,EAAY7K,EAAQxC,U,oCAItC,OAAOuN,EAAMgB,gB,iCAxCb,MAAO,4D,uCAIP,MAAO,wHAC8ClB,EAAa,sEAE3DD,EAAqB,kEAAoE,Q,KC1EjG,SAASoB,EAAmBb,GAG/B,IAFA,IAAIc,EAAWd,EAAM,GACjBe,EAAW,EACNpP,EAAI,EAAGU,EAAS2N,EAAM3N,OAAQV,EAAIU,EAAQV,IAAK,CACpD,IAAIqP,EAAIhB,EAAMrO,GACVqP,EAAIF,IACJC,EAAWpP,EACXmP,EAAWE,GAGnB,OAAOD,E,WCFLE,EAAa7M,EAAOE,aAAa,GAAKF,EAAOE,aAAa,GAC1D4M,EAAkBrM,EAAQxC,OAC1BkH,EAAU,GACV4H,EAAmB,CAAC,EAAG,I,IAaRC,G,WACjB,aAAe,oBACX5N,KAAK6N,cAAgB7N,KAAK6N,cAAcpM,KAAKzB,MAM7CA,KAAK+F,QAAUgB,OAAO+G,OALD,CACjBC,eAAgB,GAChBC,uBAAwB,KAGiBjI,GAE7C/F,KAAKiO,MArBb,WACI,IAAMA,EAAQC,MAOd,OANAD,EAAME,IAAID,IAAUE,MAAM,CAACC,WAAY,CAAC,IAAKC,MAAO,GAAIC,WAAY,UACpEN,EAAME,IAAID,IAAUE,MAAM,CAAEE,MAAO,EAAGC,WAAY,YAClDN,EAAMO,QAAQ,CACVC,UAAW,OACXC,KAAM,qBAEHT,EAaUU,GAEb3O,KAAK4O,eAAiBnB,EACtBzN,KAAK0N,gBAAkBA,EAEvB1N,KAAK6O,qBAAuB,EAE5B7O,KAAK8O,sBAAwB,KAC7B9O,KAAK+O,QAAU,CACX/G,YAAa,KACb4C,OAAQ,KACRkB,OAAQ,M,sDAeNxD,EAAYoC,EAAYC,GAC9B,IAAM3C,EAAcxI,EAAkBmL,GAEtC3K,KAAK+O,QAAU,CACX/G,YAAahI,KAAK8O,sBAClBlE,OAAQtC,EACRwD,OAAQpB,GAEZ1K,KAAK8O,sBAAwB9G,EAWI,OAA7BhI,KAAK+O,QAAQ/G,aACbhI,KAAK6N,cAAc7N,KAAK+O,QAAQ/G,YAAahI,KAAK+O,QAAQnE,OAAQ5K,KAAK+O,QAAQjD,OAAQ9D,GAG3F,IAEI4C,ECrF4BnE,EDmF5BuI,GAAkB,EAClBC,EAAgB,KAIpB,GAAIxO,KAAKC,SAAWV,KAAK+F,QAAQiI,uBCxFDvH,EDyFKzG,KAAK0N,gBAAtC9C,ECxFDnK,KAAKI,MAAMJ,KAAKC,SAAW+F,GDyF1BuI,GAAkB,EAClBC,EAAgB,CAAC,EAAG,EAAG,EAAG,OACvB,CAEH,IAAIC,EAAelP,KAAKmP,aAAanH,GACrCiH,EAAgBC,EAChBtE,EAASwE,EAA6BF,GAc1C,OAXIjC,GAASC,mBACT5B,EAAqB,CACjBV,OAAQA,EACRgB,UAAWoD,EACXvD,QAASwD,IAEM,OAAfvE,GACAmB,EAAanB,IAIdE,I,gCAIP5K,KAAK8O,sBAAwB,KAC7B9O,KAAK+O,QAAU,CACX/G,YAAa,KACb4C,OAAQ,KACRkB,OAAQ,Q,mCAIHuD,GAAmB,IAAD,OAC3B,OAAOnB,KAAQ,WACX,IAAMoB,EAAoBpB,IAAUmB,EAAkB1B,GAGtD,OAFuC,EAAKM,MAAMsB,eAAeD,GACIE,gB,iCAKlEH,EAAkBI,GACzB,IAAMH,EAAoBpB,IAAUmB,EAAkB1B,GAChD+B,EAAexB,IAAUuB,EAAiB,CAAC,EAAGzP,KAAK0N,kBACzD1N,KAAKiO,MAAM0B,aAAaL,EAAmBI,GAAcE,MAAK,SAACC,GAC3DP,EAAkBQ,UAClBJ,EAAaI,e,oCAIPC,EAAiBzH,EAAYoC,EAAYsF,GACnD,IAAMC,EAAwBjQ,KAAKkQ,yBAAyBF,GACtDG,EAASnQ,KAAKmP,aAAaY,GAC3BK,EAAoB1F,EAAauF,EAAwBjQ,KAAK+F,QAAQgI,eAC5EoC,EAAO7H,GAAc8H,EACrBpQ,KAAKqQ,WAAWN,EAAiBI,K,+CAGZH,GAAqB,IAAD,OACnCM,EAA0BtQ,KAAKmP,aAAaa,GAC5CO,EAAsBD,EAAwBlB,EAA6BkB,IAC3EE,EAAkBF,EAAwB3H,QAC5C,SAAC8H,EAAaC,GACV,OAAOD,EAAcC,EAAe,EAAKhD,mBAGjD,OAAO6C,GAAuB,EAAIvQ,KAAK+F,QAAQiI,wBACzCwC,EAAkBxQ,KAAK+F,QAAQiI,yB,mCAIrCtJ,MAAM,qB,oCAINA,MAAM,sB,iCAjHN,MAAO,uE,KEhDA,IACX,CACIiM,KAAM/C,GAAuBgD,UAC7BC,MAAOjD,IAMX,CACIiD,MAAOlE,EACPgE,KAAMhE,EAAaiE,UACnBE,YAAanE,EAAaoE,iBAC1BC,iBAAkB,KAEtB,CACIL,KAAMvH,EAAawH,UACnBC,MAAOzH,IClBT6H,GAAe,CACjBC,aAAc,EACdC,cAAe,EACfC,SAAU,EACVC,UAAW,EACXC,YAAa,EACbC,iBAAkB,EAClBC,uBAAwB,EACxBC,gBAAiB,GACjB3K,iBAAkB,GAClBD,wBAAyB,GACzB6K,kBAAmB,EACnBC,gBAAiB,EACjBC,YAAa,GAGIC,G,WACjB,WAAYC,EAAUC,GAAiB,IAAD,2BAClC/R,KAAKgS,qBAAuB,EAC5BhS,KAAKiS,mBAAoB,EACzBjS,KAAKkS,UAAYJ,EACjB9R,KAAKmS,OAASpL,OAAO+G,OAAO,GAAImD,IAChCjR,KAAKoS,gBAAkBL,EACvB/R,KAAKqS,kBAAoB,KACzBrS,KAAKsS,gBAAkB,KAGvBtS,KAAKuS,YAAc,EAEnBvS,KAAKwS,QAAUxS,KAAKwS,QAAQ/Q,KAAKzB,MACjCA,KAAKyS,WAAazS,KAAKyS,WAAWhR,KAAKzB,MACvCA,KAAK0S,KAAO1S,KAAK0S,KAAKjR,KAAKzB,MAC3BA,KAAK2S,WAAa3S,KAAK2S,WAAWlR,KAAKzB,MACvCA,KAAK4S,oBAAsB5S,KAAK4S,oBAAoBnR,KAAKzB,MAEzDA,KAAK6S,KAAO,CAAEjI,OAAQ,KAAMkB,OAAQ,MAEpCgH,aAAY,WACR,EAAKX,OAAOZ,iBAAmB,EAAKY,OAAOb,YAAc,EAAKa,OAAOX,uBACrE,EAAKW,OAAOX,uBAAyB,EAAKW,OAAOb,cAClD,K,oDAGCyB,GACJ/S,KAAKgS,uBAELhS,KAAKgT,OAASD,EAGd/S,KAAKiT,aAAe,IAAI3R,EACxBtB,KAAKmS,OAAOjB,aAAe,EACvBlR,KAAKiS,kBAGLjS,KAAKkS,UACDlS,KAAKiT,aAAavR,sBAClB1B,KAAKiT,aAAatR,oBAClB3B,KAAKgS,sBAGThS,KAAKoS,gBAAgBpS,KAAKmS,QAE9BnS,KAAKkT,wB,+CAIDlT,KAAKgT,OAAOG,YACZnT,KAAKgT,OAAOG,e,iCAQTvI,GACP,IAAIhE,EAAQ5G,KAAKmS,OACXtQ,EAAaR,EAAQuJ,GAO3B,GALmB,OAAf/I,GACA7B,KAAKiT,aAAazR,YAAYK,GAElC7B,KAAKkT,sBAEDlT,KAAKsS,gBAAgBnS,WAAY,CACjCH,KAAKgT,OAAOI,UAAUpT,KAAK6S,KAAKjI,OAAQ5K,KAAK6S,KAAK/G,OAAQ9L,KAAKqS,kBAAkBvS,WACjFE,KAAKgT,OAAOR,UACZ5L,EAAMuK,cAAgBnR,KAAKqS,kBAAkBtS,MAC7C6G,EAAM6K,gBAAgB7H,KAAK5J,KAAKqS,kBAAkBtS,OAC9C6G,EAAM6K,gBAAgB5S,OAAS,KAC/B+H,EAAM6K,gBAAgB4B,QAE1B,IAAIC,EAAwB1M,EAAM6K,gBAAgB9I,QAAO,SAAC4K,EAAKC,GAAN,OAAcD,EAAMC,IAAK,GAClF5M,EAAM8K,kBAAqB4B,EAAwB1M,EAAM6K,gBAAgB5S,QAAW,EACpF+H,EAAMwK,UAAYpR,KAAKqS,kBAAkBtS,MACzC6G,EAAME,iBAAiB8C,KAAKhD,EAAMuK,eAClCvK,EAAMC,wBAAwB+C,KAAKhD,EAAM8K,mBACzC9K,EAAMyK,WAAa,EAGfzK,EAAME,iBAAiBjI,OAAS4U,MAChC7M,EAAME,iBAAmBF,EAAME,iBAAiBtE,OAvG1C,KAwGNoE,EAAMC,wBAA0BD,EAAMC,wBAAwBrE,OAxGxD,MA2GVxC,KAAKwS,QAAQxS,KAAKgT,OAAQhT,KAAKiS,mBAG/BjS,KAAKiS,oBACLjS,KAAKkS,UAAUlS,KAAKqS,kBAAmBrS,KAAKsS,gBAAiBtS,KAAKgS,sBAClEpL,EAAMsK,aAAelR,KAAKqS,kBAAkBtS,MAC5CC,KAAKoS,gBAAgBxL,IAGzBA,EAAM0K,cACN,IAAIxF,EAAS9L,KAAKqS,kBAAkBtS,MAAQ6G,EAAM+K,gBAClD/K,EAAM+K,gBAAkB3R,KAAKqS,kBAAkBtS,MAC/C6G,EAAMgL,aAAe9F,EAErB9L,KAAK6S,KAAK/G,OAASA,EACnB9L,KAAK6S,KAAKjI,OAASA,EAEnB5K,KAAKuS,YAAcvS,KAAKgT,OAAOI,UAAUpT,KAAK6S,KAAKjI,OAAQ5K,KAAK6S,KAAK/G,OAAQ9L,KAAKqS,kBAAkBvS,a,0CAGpFoN,GAChBlN,KAAKiS,kBAAoB/E,I,gDAIzB,OAAOlN,KAAKgT,S,6BAIZhT,KAAKyS,WAAWzS,KAAKuS,e,mCAIrBvS,KAAKmS,OAASpL,OAAO+G,OAAO,GAAImD,IAChCjR,KAAKmS,OAAOV,gBAAkB,GAC9BzR,KAAKmS,OAAOrL,iBAAmB,GAC/B9G,KAAKmS,OAAOtL,wBAA0B,K,4CAItC7G,KAAKqS,kBAAoBrS,KAAKiT,aAAavR,sBAC3C1B,KAAKsS,gBAAkBtS,KAAKiT,aAAatR,wB,KClJ5B+R,G,iLAEb,IAAM9M,EAAQ5G,KAAKmD,MAAMyD,MACzB,OACI,+BACI,+BACCG,OAAOC,KAAKJ,GAAOnD,KAAI,SAACG,GAAD,OACpB,wBAAIA,IAAKA,GACL,4BAAKA,EAAL,KAAYgD,EAAMhD,c,GARAK,aCQ7BgJ,GAAW,CAGpBC,kBAAkB,EAClByG,MAAO,IACPC,iCAAkC,IAClCC,UAAU,GAGOC,G,YACjB,aAAe,IAAD,8BACV,+CACKC,cAAgB,EAAKA,cAActS,KAAnB,gBACrB,EAAKuS,6BAA+B,EAAKA,6BAA6BvS,KAAlC,gBACpC,EAAKwS,0BAA4B,EAAKA,0BAA0BxS,KAA/B,gBACjC,EAAKyS,yBAA2B,EAAKA,yBAAyBzS,KAA9B,gBAChC,EAAK0S,0BAA4B,EAAKA,0BAA0B1S,KAA/B,gBACjC,EAAK2S,sBAAwB,EAAKA,sBAAsB3S,KAA3B,gBAC7B,EAAK4S,2BAA6B,EAAKA,2BAA2B5S,KAAhC,gBAClC,EAAK6S,yBAA2B,EAAKA,yBAAyB7S,KAA9B,gBAEhC,EAAK8S,QAAUC,GACf,EAAKC,eAAiB,GAEtB,EAAKC,UAAYzH,GAEjB,EAAK9K,MAAQ,CACTwS,eAAgB,GAChBvR,iBAAkB,KAClBX,eAAgB,KAChBmS,oBAAqB,EACrBC,kBAAmB,EACnBlB,MAAO,EAAKe,UAAUf,MACtBmB,qBAAsB,EACtBC,0BAA2B,EAC3BC,sBAAuB,MAzBjB,E,kFA+BVhV,KAAKiV,YAAc,IAAIpD,GAAW7R,KAAKkU,yBAA0BlU,KAAKgU,8BAEtEhU,KAAKkV,uBACLlV,KAAK+T,kB,+CAGgB3Q,EAAkBX,EAAgBmS,GACvD5U,KAAKuC,SAAS,CACVa,iBAAkBA,EAClBX,eAAgBA,EAChBmS,oBAAqBA,M,mDAIAhO,GACzB,IAAIuO,GAAmB,IAAIC,MAAQC,UAiBnC,GAhBIF,EAAkBnV,KAAKmC,MAAM2S,qBAAuB,KACpD9U,KAAKuC,SAAS,CACVoS,eAAgB,CAEZ,gBAAiB/N,EAAMsK,aAAa1J,QAAQ,GAC5C,qBAAsBZ,EAAM2K,iBAAiB+D,iBAC7C,wBAAyB1O,EAAMuK,cAAc3J,QAAQ,GACrD,iCAAkCZ,EAAM8K,kBAAkBlK,QAAQ,GAClE,kCAAoCZ,EAAMwK,SAAWxK,EAAMyK,WAAc,GAAG7J,QAAQ,GAEpF,aAAcZ,EAAMyK,UAAUiE,kBAElCR,qBAAsBK,IAI1BA,EAAkBnV,KAAKmC,MAAM4S,0BAA4B,GAAI,CAE7D,GAAI9H,GAASC,iBACT,OAGJlN,KAAKuC,SAAS,CACVyS,sBAAuBpO,EACvBmO,0BAA2BI,O,sCAOnC,IAAII,EAAOvV,KAEX,GADAwV,cAAcxV,KAAKyV,oBACfzV,KAAK0U,UAAUb,SAAU,CACzB,IAAI7C,EAAmBhR,KAAK0U,UAAUd,iCAClC5T,KAAKuU,QAAQvU,KAAKmC,MAAM0S,mBAAmB7D,mBAE3CA,EAAmBhR,KAAKuU,QAAQvU,KAAKmC,MAAM0S,mBAAmB7D,kBAE9DhR,KAAK0U,UAAUxH,mBACf8D,EAAmB,GAGvBhR,KAAKyV,mBAAqB3C,aAAY,WAClC,IAAK,IAAI3U,EAAI,EAAGA,EAAI6S,EAAkB7S,IAClCoX,EAAKN,YAAYvC,SAEtB1S,KAAK0U,UAAUf,U,6CAKtB3T,KAAKiV,YAAYrC,oBAAoB5S,KAAK0U,UAAUxH,kBACpDlN,KAAKiV,YAAYtC,aACZ3S,KAAKyU,eAAezU,KAAKmC,MAAM0S,qBAChC7U,KAAKyU,eAAezU,KAAKmC,MAAM0S,mBAAqB,IAAI7U,KAAKuU,QAAQvU,KAAKmC,MAAM0S,mBAAmBhE,OAEvG7Q,KAAKiV,YAAYzC,QAAQxS,KAAKyU,eAAezU,KAAKmC,MAAM0S,mBAAoB7U,KAAK0U,UAAUxH,oB,+BAGtFlI,GACLhF,KAAKuC,SAAS,CAAEoR,MAAO3O,IACvB,IAAI0Q,GAA0B,EAC9B1V,KAAK0U,UAAUb,UAAW,EACZ,cAAV7O,GACA0Q,GAA0B,EAC1B1V,KAAK0U,UAAUf,MAAQ,GACN,WAAV3O,EACPhF,KAAK0U,UAAUb,UAAW,EAE1B7T,KAAK0U,UAAUf,MAAQ3O,EAEvB0Q,IAA4B1V,KAAK0U,UAAUxH,mBAC3ClN,KAAK0U,UAAUxH,iBAAmBwI,EAClC1V,KAAKiV,YAAYrC,oBAAoB5S,KAAK0U,UAAUxH,mBAExDlN,KAAK+T,kB,gDAGiB4B,GACtB3V,KAAK4V,SAASD,EAAMxF,OAAOnL,S,yCAIZ6Q,EAAWC,GACtBA,EAAUjB,oBAAsB7U,KAAKmC,MAAM0S,oBAE3C7U,KAAKkV,uBACLlV,KAAK+T,mB,gDAIa4B,GACtB3V,KAAKuC,SAAS,CAAEsS,kBAAmBc,EAAMxF,OAAOnL,U,8CAIhDhF,KAAKiV,YAAYc,yBACjB/V,KAAKkV,yB,iDAGkBS,GACvB,IAAM/K,EAASvJ,EAAQ8H,QAAQwM,EAAM/R,MACrB,IAAZgH,GACA5K,KAAKiV,YAAYxC,WAAW7H,K,iDAKhC5K,KAAK4V,SAAS,Y,+BAId,OACI,6BACI,yBAAKI,GAAG,QAAR,SACI,4BAAQC,SAAUjW,KAAKmU,2BAClBnU,KAAKuU,QAAQ9Q,KAAK,SAAC2I,EAAO8J,GAAR,OACf,4BAAQtS,IAAKsS,EAAOlR,MAAOkR,GAAQ9J,EAAMuE,UAHrD,OAQI,4BAAQhM,QAAS3E,KAAKoU,uBAAtB,2BACA,6BATJ,SAWI,4BAAQ6B,SAAUjW,KAAKiU,0BAA2BjP,MAAOhF,KAAKmC,MAAMwR,OAChE,4BAAQ3O,MAAM,aAAd,kCACA,4BAAQA,MAAM,KAAd,aACA,4BAAQA,MAAM,OAAd,QACA,4BAAQA,MAAM,OAAd,UACA,4BAAQA,MAAM,OAAd,QACA,4BAAQA,MAAM,UAAd,WAjBR,OAoBI,4BAAQO,KAAK,OACT4Q,UAAWnW,KAAKqU,2BAChB1P,QAAS3E,KAAKsU,0BAFlB,gCAIA,yBAAK0B,GAAG,UACR,kBAAC,GAAD,CAAcpP,MAAO5G,KAAKmC,MAAMwS,iBAChC,+BAEF3U,KAAK0U,UAAUxH,kBAAoBlN,KAAKmC,MAAM6S,uBAC5C,yBAAKjR,MAAO,CAAEe,MAAO,SACjB,kBAAC,EAAD,CAAmB8B,MAAO5G,KAAKmC,MAAM6S,yBAG5ChV,KAAK0U,UAAUxH,kBAAoBlN,KAAKmC,MAAMiB,kBAC3C,6BACI,kBAAC,EAAD,CACIA,iBAAkBpD,KAAKmC,MAAMiB,iBAC7BX,eAAgBzC,KAAKmC,MAAMM,eAC3BL,WAAYpC,KAAKmC,MAAMyS,sBAE3B,yBAAKoB,GAAG,2BACPhW,KAAKuU,QAAQvU,KAAKmC,MAAM0S,mBAAmB/D,aACxC,6BACK9Q,KAAKuU,QAAQvU,KAAKmC,MAAM0S,mBAAmB/D,cAK5D,6BACA,kBAAC,EAAD,CAAkBvJ,kBAAmBA,IACrC,6BACA,kBAAC,EAAD,CAAmBlD,WAAYrE,KAAKiV,mB,GAtNnBhR,a,MCfjCmS,IAASC,OACP,kBAAC,GAAD,MACAlL,SAASC,eAAe,W","file":"static/js/main.08285ad0.chunk.js","sourcesContent":["/**\n * Creates a matrix out of nested Float32Arrays and returns it\n *\n * @param {Array} dimensions [xLength, yLength]\n * @returns {Array}\n */\nexport function createMatrix(dimensions) {\n    let matrix = [];\n\n    for (let i = 0; i < dimensions[0]; i++) {\n        matrix[i] = new Float32Array(dimensions[1]);\n    }\n\n    return matrix;\n}\n\n/**\n * Shifts and trims the given matrix by the given amounts. Is useful for creating viewport output.\n *\n * @param matrix\n * @param shiftVector\n * @param defaultValue\n * @param trimVector\n * @param outputMatrix Output is written here rather than returned because instantiating arrays is slow in JS\n * @returns {*}\n */\nexport function shiftAndTrimMatrix(matrix, shiftVector, defaultValue, trimVector, outputMatrix) {\n    shiftVector = [shiftVector[0] + trimVector[0], shiftVector[1] + trimVector[1]];\n    var shiftX = shiftVector[0];\n    var shiftY = shiftVector[1];\n    var fromXLen = matrix.length;\n    var fromYLen = matrix[0].length;\n    var xLen = fromXLen - trimVector[0] * 2;\n    var yLen = fromYLen - trimVector[1] * 2;\n    if (outputMatrix.length !== xLen || outputMatrix[0].length !== yLen) {\n        throw new Error('Output matrix has the wrong dimensions. ' +\n            'Expected:'+xLen+'x'+yLen+' ,' +\n            'Actual:'+outputMatrix.length+'x'+outputMatrix[0].length);\n    }\n\n    for (var x = 0; x < xLen; x++) {\n        var fromX = x + shiftX;\n        var fromXRow = matrix[fromX];\n        var toXRow = outputMatrix[x];\n        for (var y = 0; y < yLen; y++) {\n            var fromY = y + shiftY;\n            if (fromX >= 0 && fromX < fromXLen && fromY >= 0 && fromY < fromYLen) {\n                toXRow[y] = fromXRow[y + shiftY]\n            } else {\n                toXRow[y] = defaultValue;\n            }\n        }\n    }\n\n    //Thought this may be faster but it was not\n    // for (var x = 0; x < xLen; x++) {\n    //     for (var y = 0; y < yLen; y++) {\n    //         if (x + shiftX >= 0 && x + shiftX < fromXLen && y + shiftY >= 0 && y + shiftY < fromYLen) {\n    //             outputMatrix[x][y] = matrix[x + shiftX][y + shiftY]\n    //         } else {\n    //             outputMatrix[x][y] = defaultValue;\n    //         }\n    //     }\n    // }\n}\n\n/**\n * Converts a matrix made of nested arrays to a single flat array and returns it\n *\n * @param {Array} matrix\n * @returns {Float32Array}\n */\nexport function matrixToFlatArray(matrix) {\n    const xLen = matrix.length;\n    const yLen = matrix[0].length;\n    var vectorI = 0;\n    // var vector = new Float32Array(xLen * yLen);\n    var vector = new Float32Array(xLen * yLen);\n    // var vector = [];\n    for (var xI = 0; xI < xLen; xI++) {\n        for (var yI = 0; yI < yLen; yI++) {\n            vector[vectorI] = matrix[xI][yI];\n            vectorI++;\n        }\n    }\n    return vector;\n}\n","/**\n * Data model that holds what the agent gets to see about the environment\n */\nexport default class AgentObservation {\n    /**\n     *\n     * @param {Array} tileTypes\n     * @param {int} score\n    //  * @param {Array} position\n     */\n    constructor(tileTypes, score/*, position*/) {\n        /**\n         * @type {Array}\n         */\n        this.tileTypes = tileTypes;\n\n        /**\n         * @type {Number}\n         */\n        this.score = score;\n\n        // /**\n        //  *\n        //  * @type {Array} A vector contained the X and Y of the current agent position\n        //  */\n        // this.position = position;\n    }\n}\n","/**\n * Data model that holds the environment's full internal state\n */\nexport default class State {\n    /**\n     * @param {Array} tileTypes\n     * @param {Array} position [x,y]\n     * @param {Number} score\n     * @param {Boolean} isComplete\n     */\n    constructor(tileTypes, position, score, isComplete) {\n        /**\n         * @type {Array}\n         */\n        this.tileTypes = tileTypes;\n        /**\n         * @type {Array} position [x,y]\n         */\n        this.position = position;\n        /**\n         * @type {Number}\n         */\n        this.score = score;\n        /**\n         * @type {Boolean}\n         */\n        this.isComplete = isComplete;\n    }\n}\n","import State from './State'\nimport {config} from './index'\n\n/**\n * Returns a random initial starting state\n *\n * @returns {State}\n */\nexport const generateInitialState = () => {\n    return new State(\n        generateRandomTileTypes(config.size),\n        [Math.floor(config.size[0] / 2), 0],\n        0,\n        false\n    );\n};\n\n/**\n * Generates a random set of tileTypes for generated random environment states\n *\n * @param {Array} size\n * @returns {Array}\n */\nfunction generateRandomTileTypes(size) {\n    const tileTypes = [];\n    var xLen = size[0];\n    var yLen = size[1];\n    for (var xi = 0; xi < xLen; xi++) {\n        tileTypes[xi] = new Array(yLen);\n        for (var yi = 0; yi < size[1]; yi++) {\n            // tileTypes[xi][yi] = Math.random() < 0.7 ? 0 : 1;\n            tileTypes[xi][yi] = Math.random() < 0.2 ? 1 : 0;\n        }\n    }\n    return tileTypes;\n}\n","import { shiftAndTrimMatrix, createMatrix } from './nestedFloatMatrixMath'\nimport AgentObservation from './AgentObservation'\nimport { generateInitialState } from './generateInitialState'\nconst easyMode = true;\nexport const config = {\n    //Environment size\n    size: [31, 31],\n\n    //Viewport settings\n    viewPortSize: [9, 9],\n    viewPortOffset: [0, 2],\n    viewPortPosition: [4, 2],\n\n    //Scoring settings\n    verticalDeltaScore: easyMode ? 0.01 : 0,\n    deltaScorePerAction: -0.01,\n    tileTypeToDeltaScore: [0, -0.2],\n    getToBottomDeltaScore: 1,\n    // maxDeltaScoreAbs: 1000\n};\n\nexport const actions = ['w', 'a', 's', 'd'];\n\n/**\n * The main environment class for this game. This is the public interface for the game.\n */\nexport default class Environment {\n    constructor() {\n        this._state = generateInitialState();\n\n        //Bind these to create proper JavaScript \"this\" context\n        this.applyAction = this.applyAction.bind(this);\n        this.getAgentObservation = this.getAgentObservation.bind(this);\n        this.getGodObservation = this.getGodObservation.bind(this);\n\n        //This viewport output matrix is only instantiated once to increase performance\n        this.viewportOutputMatrix = createMatrix(config.viewPortSize);\n    }\n\n    /**\n     * Mutates the environment's internal state by processing the given action\n     *\n     * @param actionCode\n     */\n    applyAction(actionCode) {\n        var deltaScoreFromHittingEdge = 0;\n        switch (actionCode) {\n            case \"w\":\n                if (this._state.position[1] > 0) {\n                    this._state.position[1]--;\n                    this._state.score -= config.verticalDeltaScore;\n                } else {\n                    deltaScoreFromHittingEdge = config.tileTypeToDeltaScore[1];//Edges are tileType 1 (red)\n                }\n                break;\n            case \"a\":\n                if (this._state.position[0] > 0) {\n                    this._state.position[0]--;\n                } else {\n                    deltaScoreFromHittingEdge = config.tileTypeToDeltaScore[1];//Edges are tileType 1 (red)\n                }\n                break;\n            case \"s\":\n                this._state.position[1]++;\n                this._state.score = this._state.score + config.verticalDeltaScore;\n                break;\n            case \"d\":\n                if (this._state.position[0] < config.size[0] - 1) {\n                    this._state.position[0]++;\n                } else {\n                    deltaScoreFromHittingEdge = config.tileTypeToDeltaScore[1];//Edges are tileType 1 (red)\n                }\n                break;\n            default:\n                throw new Error('Unknown action: ' + actionCode)\n        }\n\n        const tileType = this._state.tileTypes[this._state.position[0]][this._state.position[1]];\n\n        this._state.score +=\n            config.tileTypeToDeltaScore[tileType] +\n            config.deltaScorePerAction +\n            deltaScoreFromHittingEdge;\n\n        this._state.isComplete = this._state.position[1] === config.size[1] - 1;\n        if (this._state.isComplete) {\n            this._state.score += config.getToBottomDeltaScore\n        }\n    }\n\n    /**\n     * Returns what the agent can see about the current environment state\n     *\n     * @returns {AgentObservation}\n     */\n    getAgentObservation() {\n        const shiftVector = [\n            Math.ceil(this._state.position[0] - config.size[0] / 2),\n            Math.ceil(this._state.position[1] - config.size[0] / 2) + config.viewPortOffset[1]\n        ];\n        const trimVector = [\n            Math.floor((config.size[0] - config.viewPortSize[0]) / 2),\n            Math.floor((config.size[1] - config.viewPortSize[1]) / 2)\n        ];\n\n        shiftAndTrimMatrix(this._state.tileTypes, shiftVector, 1, trimVector, this.viewportOutputMatrix);\n\n        //Make the bottom exit edge look safe by making its tiles not red\n        const limit = config.size[1] - trimVector[1] - shiftVector[1];\n        if (limit < config.viewPortSize[1]) {\n            for (var x = 0; x < config.viewPortSize[0]; x++) {\n                for (var y = limit; y < config.viewPortSize[1]; y++) {\n                    this.viewportOutputMatrix[x][y] = 0;\n                }\n            }\n        }\n\n        return new AgentObservation(\n            this.viewportOutputMatrix,\n            this._state.score//,\n            // config.viewPortPosition\n        );\n    }\n\n    getGodObservation() {\n        return this._state\n    }\n}\n","// import * as viewportConversions from './../environment/viewportConversions'\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { config } from '../environment';\nexport default class ObservationRenderer extends Component {\n    constructor() {\n        super();\n        this.state = {\n            gameNumber: 0,\n            previousPositions: [] //Stores the \"trail\" of where we have been on the environment view\n        }\n    }\n\n    componentWillReceiveProps(nextProps) {\n        if (nextProps.gameNumber !== this.state.gameNumber) {\n            //We are in a new game so clear previously saved \"previous positions trail\"\n            this.setState({\n                gameNumber: nextProps.gameNumber,\n                previousPositions: []\n            });\n        } else {\n            //We are in the same game as before so add to the current \"previous positions trail\"\n            const previousPositions = this.state.previousPositions.slice();//Make copy to preserve immutability\n            const scalarPosition =\n                nextProps.godObservation.position[0] * nextProps.godObservation.tileTypes.length\n                + nextProps.godObservation.position[1];\n            previousPositions[scalarPosition] = true;\n            this.setState({\n                previousPositions: previousPositions\n            });\n        }\n    }\n\n    render() {\n        const agentTileColors = calculateAgentTileColors(\n            // viewportConversions.convert9x9to5x3(this.props.agentObservation.tileTypes),\n            this.props.agentObservation.tileTypes,\n            // [2, 0]\n            // this.props.agentObservation.position,\n            config.viewPortPosition\n        );\n        const godTileColors = calculateGodTileColors(\n            this.props.godObservation.tileTypes,\n            this.props.godObservation.position,\n            this.state.previousPositions\n        );\n\n        return <div className=\"InfectionGameHtmlTableRender\">\n            <div>\n                <span>Agent View</span>\n                <table className=\"renderer-table-canvas-agent\">\n                    <tbody>\n                        {agentTileColors.map((row, rowIndex) =>\n                            <tr key={rowIndex}>\n                                {row.map((tileColor, tileIndex) =>\n                                    <td key={tileIndex} style={{ backgroundColor: tileColor }} />\n                                )}\n                            </tr>\n                        )}\n                    </tbody>\n                </table>\n            </div>\n            <div>\n                <span>Environment View</span>\n                <table className=\"renderer-table-canvas-god\">\n                    <tbody>\n                        {godTileColors.map((row, rowIndex) =>\n                            <tr key={rowIndex}>\n                                {row.map((tileColor, tileIndex) =>\n                                    <td key={tileIndex} style={{ backgroundColor: tileColor }} />\n                                )}\n                            </tr>\n                        )}\n                    </tbody>\n                </table>\n            </div>\n        </div>;\n    };\n}\n\nObservationRenderer.propTypes = {\n    agentObservation: PropTypes.object.isRequired,\n    godObservation: PropTypes.object.isRequired,\n    gameNumber: PropTypes.number.isRequired\n};\n\nfunction calculateGodTileColors(tileTypes, position, previousPositions) {\n    const tileColors = [];\n    const xLength = tileTypes.length;\n    const yLength = tileTypes[0].length;\n    for (let x = 0; x < xLength; x++) {\n        for (let y = 0; y < yLength; y++) {\n            let scalarPosition = x * xLength + y;\n            let inPreviousPosition = previousPositions[scalarPosition];\n            let color = { r: 50, g: 50, b: 50 };\n            if (x === position[0] && y === position[1] && tileTypes[x][y] !== 0) {\n                color = { r: 255, g: 255, b: 0 };\n            } else if (x === position[0] && y === position[1]) {\n                color = { r: 0, g: 255, b: 0 };\n            } else if (inPreviousPosition && tileTypes[x][y] !== 0) {\n                color = { r: 255, g: 255, b: 128 }\n            } else if (inPreviousPosition) {\n                color = { r: 0, g: 128, b: 0 }\n            } else if (tileTypes[x][y] !== 0) {\n                color = { r: 230, g: 0, b: 0 };\n            }\n            if (!tileColors[y]) {\n                tileColors[y] = [];\n            }\n            tileColors[y][x] = 'rgb(' + color.r + ',' + color.g + ',' + color.b + ')';\n        }\n    }\n\n    return tileColors;\n}\n\nfunction calculateAgentTileColors(tileTypes, position) {\n    const tileColors = [];\n    const xLength = tileTypes.length;\n    const yLength = tileTypes[0].length;\n    for (let x = 0; x < xLength; x++) {\n        for (let y = 0; y < yLength; y++) {\n            let color = { r: 50, g: 50, b: 50 };\n            if (x === position[0] && y === position[1] && tileTypes[x][y] !== 0) {\n                color = { r: 255, g: 255, b: 0 };\n            } else if (x === position[0] && y === position[1]) {\n                color = { r: 0, g: 255, b: 0 };\n            } else if (tileTypes[x][y] !== 0) {\n                color = { r: 230, g: 0, b: 0 };\n            }\n            if (!tileColors[y]) {\n                tileColors[y] = [];\n            }\n            tileColors[y][x] = 'rgb(' + color.r + ',' + color.g + ',' + color.b + ')';\n        }\n    }\n    return tileColors;\n}\n","import React, {Component} from 'react';\nimport PropTypes from 'prop-types'\n\nexport default class BrainExportButton extends Component {\n    constructor() {\n        super();\n        this.onExportButtonClick = this.onExportButtonClick.bind(this);\n        this.state = {exportData: null};\n    }\n\n    onExportButtonClick() {\n        const gameRunner = this.props.gameRunner;\n        if (!gameRunner.getCurrentAgentInstance().exportBrain) {\n            alert('Current agent has no exportBrain() function.');\n            return;\n        }\n\n        this.setState({\n            exportData: 'export const data = JSON.parse(\\'' +\n            JSON.stringify(gameRunner.getCurrentAgentInstance().exportBrain()) +\n            '\\');'\n        });\n    }\n\n    render() {\n        return (\n            <div>\n                <button onClick={this.onExportButtonClick}>Export Agent Brain</button>\n                {this.state.exportData &&\n                <div>\n                    <br/>\n                    <div>Exported Agent Brain Data:</div>\n                    <textarea\n                        autoFocus\n                        readOnly\n                        style={{width: '100%', height: '10em'}}\n                        value={this.state.exportData}/>\n                </div>\n                }\n            </div>\n        );\n    }\n}\n\nBrainExportButton.propTypes = {\n    gameRunner: PropTypes.object.isRequired\n};\n\n","import React, {Component} from 'react';\nimport PropTypes from 'prop-types'\nimport Chart from 'chart.js'\n\nconst chartGameCount = 200;\n\nexport default class ScoreHistoryChart extends Component {\n    componentDidMount() {\n        let chartCanvas = this.refs.chart;\n\n        let myChart = new Chart(chartCanvas, {\n            type: 'line',\n            data: {\n                labels: [],\n                datasets: [\n                    {\n                        label: 'Average Final Score',\n                        data: [],\n                        backgroundColor: 'transparent',\n                        borderColor: 'blue',\n                        borderWidth: 1,\n                        lineTension: 0\n                    },\n                    {\n                        label: 'Final Score',\n                        data: [],\n                        backgroundColor: 'transparent',\n                        borderColor: 'lightgrey',\n                        borderWidth: 1,\n                        lineTension: 0\n                    },\n                ]\n            },\n            options: {\n                animation: {\n                    duration: 0\n                },\n                elements: {point: {radius: 0}},\n                scales: {\n                    yAxes: [{\n                        ticks: {\n                            min: -1,\n                            max: 1\n                        }\n                    }],\n                    xAxes: [{\n                        display: false\n                    }]\n                }\n            }\n        });\n\n        this.setState({chart: myChart});\n    }\n\n    mapStatsToChartData(stats) {\n        return {\n            datasets: [\n                {\n                    data: stats.gameCountToAverageScore.slice(-chartGameCount),\n                },\n                {\n                    data: stats.gameCountToScore.slice(-chartGameCount),\n                },\n            ],\n            labels: Object.keys(stats.gameCountToScore).slice(-chartGameCount)\n        }\n    }\n\n    componentDidUpdate() {\n        const chart = this.state.chart;\n        const data = this.mapStatsToChartData(this.props.stats);\n\n        data.datasets.forEach((dataset, i) => chart.data.datasets[i].data = dataset.data);\n\n        chart.data.labels = data.labels;\n        chart.update();\n    }\n\n\n    render() {\n        return (\n            <canvas ref={'chart'} height={'300'} width={'700'}></canvas>\n        );\n    }\n}\n\nScoreHistoryChart.propTypes = {\n    stats: PropTypes.object.isRequired\n};\n\n","import React, { Component } from 'react';\nimport PropTypes from 'prop-types'\n\nexport default class GameRulesDisplay extends Component {\n    render() {\n        const environmentConfig = this.props.environmentConfig;\n        return (\n            <div>\n                Game Rules:\n                <ul>\n                    <li>Get to the bottom row to finish the game</li>\n                    <li>Gain {environmentConfig.getToBottomDeltaScore.toFixed(3)} reward for getting to the bottom</li>\n                    <li>Lose {(-environmentConfig.tileTypeToDeltaScore[1]).toFixed(3)} reward when moving into a red square</li>\n                    {environmentConfig.deltaScorePerAction !== 0 &&\n                        <li>Lose {(-environmentConfig.deltaScorePerAction).toFixed(3)} reward for every move</li>\n                    }\n                    {environmentConfig.verticalDeltaScore !== 0 &&\n                        <li>Gain {environmentConfig.verticalDeltaScore.toFixed(3)} reward for every row lower you go</li>\n                    }\n                    {environmentConfig.verticalDeltaScore !== 0 &&\n                        <li>Lose {environmentConfig.verticalDeltaScore.toFixed(3)} reward for every row higher you go</li>\n                    }\n                </ul>\n            </div>\n        );\n    }\n}\n\nGameRulesDisplay.propTypes = {\n    environmentConfig: PropTypes.object.isRequired\n};\n\n","import {config, actions} from '../../environment'\n\nexport const oppositeActions = {\n    w: 's',\n    a: 'd',\n    s: 'w',\n    d: 'a'\n};\n\nconst actionVectors = {\n    //[dX, dY, dScore]\n    w: [0, -1, config.deltaScorePerAction - config.verticalDeltaScore],\n    a: [-1, 0, config.deltaScorePerAction],\n    s: [0, 1, config.deltaScorePerAction + config.verticalDeltaScore],\n    d: [1, 0, config.deltaScorePerAction],\n};\nexport function getFeelerValue(observation, feelerSteps) {\n    // let position = [observation.position[0], observation.position[1]];\n    let position = config.viewPortPosition;\n    let value = 0;\n    feelerSteps.forEach((step) => {\n        const vector = actionVectors[step];\n        position = [position[0] + vector[0], position[1] + vector[1]];\n        let cost;\n        if (typeof observation[position[0]] === 'undefined' || typeof observation[position[0]][position[1]] === 'undefined') {\n            cost = config.tileTypeToDeltaScore[1]; //If going off map, make look very expensive\n        } else {\n            cost = config.tileTypeToDeltaScore[observation[position[0]][position[1]]]\n        }\n        value = value + vector[2] + cost;\n    });\n    return value;\n}\n\nexport function getFeelerValues(observation, feelerPaths) {\n    return feelerPaths.map((feelerPath) => {\n        return {\n            path: feelerPath,\n            value: getFeelerValue(observation, feelerPath)\n        }\n    });\n}\n\nexport function filterPathsWithFirstAction(paths, blacklistedFirstAction) {\n    return paths.filter((path) => path[0] !== blacklistedFirstAction);\n}\n\nexport function getBestFeeler(feelersWithValues) {\n    return feelersWithValues.reduce((bestFeelerSoFar, feeler) => {\n        if (bestFeelerSoFar === null || feeler.value > bestFeelerSoFar.value) {\n            return feeler;\n        } else {\n            return bestFeelerSoFar\n        }\n    }, null)\n}\n\nexport function getActionViaFeelers(observation, feelerPaths, lastAction) {\n    //This filter prevents infinite back-and-forth movement\n    const safeFeelerPaths = filterPathsWithFirstAction(\n        feelerPaths, oppositeActions[lastAction]\n    );\n\n    const feelersWithValues = getFeelerValues(observation, safeFeelerPaths);\n\n    const bestFeeler = getBestFeeler(feelersWithValues);\n\n    return actions.indexOf(bestFeeler.path[0]);\n}\n","import { getActionViaFeelers } from './helper/feeler'\nimport generateFeelerPaths from './helper/generateFeelerPathsXByThree'\nexport default class LookAhead9x3 {\n    constructor() {\n        this._state = { lastAction: null };\n        this.feelerPaths = generateFeelerPaths(4);\n    }\n\n    static getName() {\n        return 'HandProgrammed - LookAhead - 9x3 - ranked 0.956';\n    }\n\n    getAction(lastAction, lastReward, observationMatrix) {\n        let action = getActionViaFeelers(observationMatrix, this.feelerPaths, this._state.lastAction);\n\n        this._state.lastAction = action;\n\n        return action;\n    }\n\n    newGame() { }\n}\n","export default function generateFeelerPaths(maxSidewaysMoves) {\n    const permutator = (inputArr) => {\n        let result = [];\n        const permute = (arr, m = []) => {\n            if (arr.length === 0) {\n                result.push(m)\n            } else {\n                for (let i = 0; i < arr.length; i++) {\n                    let curr = arr.slice();\n                    let next = curr.splice(i, 1);\n                    permute(curr.slice(), m.concat(next))\n                }\n            }\n        }\n        permute(inputArr)\n        return result;\n    }\n\n    let feelerPaths = [['s', 's']];\n    let leftPaths = ['s', 's'];\n    let rightPaths = ['s', 's'];\n    for (var i = 0; i < maxSidewaysMoves; i++) {\n        leftPaths.push('a');\n        rightPaths.push('d');\n        feelerPaths = feelerPaths.concat(permutator(leftPaths), permutator(rightPaths));\n    }\n\n    //Remove duplicate paths\n    feelerPaths = [...new Set(feelerPaths.map(path => path.join(',')))].map(path => path.split(','));\n\n    //Remove paths that don't end with a down action\n    feelerPaths = feelerPaths.filter(path => path[path.length - 1] === 's');\n\n    feelerPaths = feelerPaths.sort((a, b) => {\n        const aString = a.join();\n        const bString = b.join();\n        if (aString < bString) { return -1; }\n        if (aString > bString) { return 1; }\n        return 0;\n    });\n\n    return feelerPaths;\n}","import {shiftAndTrimMatrix, createMatrix} from './nestedFloatMatrixMath'\n\n// export function convert9x9to5x5(matrix) {\n//     return shiftAndTrimMatrix(matrix, [0, -1], 1, [2, 2])\n// }\n\nvar convert9x9to7x5OutputMatrix = createMatrix([7, 5]);//Object pool to increase performance\nexport function convert9x9to7x5(matrix) {\n    shiftAndTrimMatrix(matrix, [0, -1], 1, [1, 2], convert9x9to7x5OutputMatrix);\n    return convert9x9to7x5OutputMatrix;\n}\n\nvar convert9x9to5x5OutputMatrix = createMatrix([5, 5]);//Object pool to increase performance\nexport function convert9x9to5x5(matrix) {\n    shiftAndTrimMatrix(matrix, [0, -1], 1, [2, 2], convert9x9to5x5OutputMatrix);\n    return convert9x9to5x5OutputMatrix;\n}\n\nvar convert9x9to5x3OutputMatrix = createMatrix([5, 3]);//Object pool to increase performance\nexport function convert9x9to5x3(matrix) {\n    shiftAndTrimMatrix(matrix, [0, -1], 1, [2, 3], convert9x9to5x3OutputMatrix);\n    return convert9x9to5x3OutputMatrix;\n}\n\n// var convert9x9to5x2OutputMatrix = createMatrix([5, 2]);//Object pool to increase performance\n// export function convert9x9to5x2(matrix) {\n//     shiftAndTrimMatrix(matrix, [0, -0], 1, [2, 2], convert9x9to5x2OutputMatrix);\n//     return convert9x9to5x2OutputMatrix;\n// }\n\n// var convert9x9to3x2OutputMatrix = createMatrix([3, 2]);//Object pool to increase performance\n// export function convert9x9to3x2(matrix) {\n//     shiftAndTrimMatrix(matrix, [0, -0], 1, [3, 2], convert9x9to3x2OutputMatrix);\n//     return convert9x9to3x2OutputMatrix;\n// }\n","let actionElements = null;\nlet randomActionElement = null;\nlet rewardElements = null;\nlet randomActionValueElement;\n\n\nfunction ensureElementsExist() {\n    if (document.getElementById('DQNRender') && actionElements !== null) {\n        return;\n    }\n    document.getElementById('agentRendererContainer').innerHTML =\n        `<div id=\"DQNRender\">\nPredicted expected reward from each action:\n    <div style=\"overflow: auto\"><div style=\"float: left\">w:&nbsp;</div> <div id=\"action0\" style=\"background-color: lightgoldenrodyellow\"></div></div>\n    <div style=\"overflow: auto\"><div style=\"float: left\">a:&nbsp;</div> <div id=\"action1\" style=\"background-color: lightsalmon\"></div></div>\n    <div style=\"overflow: auto\"><div style=\"float: left\">s:&nbsp;</div> <div id=\"action2\" style=\"background-color: lightskyblue\"></div></div>\n    <div style=\"overflow: auto\"><div style=\"float: left\">d:&nbsp;</div> <div id=\"action3\" style=\"background-color: lightseagreen\"></div></div>\n        <div style=\"overflow: auto\"><div style=\"float: left\">random action:&nbsp;<span id=\"actionRandomValue\"></span></div><div id=\"actionRandom\" style=\"background-color: lightcoral;height: 1em\"></div></div>\n        <br>\n        Reward from last action:\n        <div style=\"overflow: auto\"><div style=\"float: left\">good&nbsp;</div> <div id=\"good\" style=\"background-color: greenyellow\"></div></div>\n    <div style=\"overflow: auto\"><div style=\"float: left\">bad&nbsp;</div> <div id=\"bad\" style=\"background-color: orangered\"></div></div>\n<br />\n</div>`;\n    actionElements = [\n        document.getElementById('action0'),\n        document.getElementById('action1'),\n        document.getElementById('action2'),\n        document.getElementById('action3'),\n    ];\n    randomActionElement = document.getElementById('actionRandom');\n    randomActionValueElement = document.getElementById('actionRandomValue');\n    rewardElements = [\n        document.getElementById('good'),\n        document.getElementById('bad'),\n    ];\n}\n\nexport function renderActionResponse(actionResponse) {//@TODO move out\n    ensureElementsExist();\n    const barFrontPadding = 100;\n    const maxActionValue = 1;//actionResponse.weights[maxAction];\n\n    const minActionValue = -1;\n    for (var i = 0, len = actionResponse.weights.length; i < len; i++) {\n        let fixedValue = (actionResponse.weights[i] - minActionValue);\n        if (fixedValue < minActionValue) {\n            fixedValue = 0;\n        } else if (fixedValue > maxActionValue * 2) {\n            fixedValue = maxActionValue * 2;\n        }\n        fixedValue += 1\n        actionElements[i].style.width = (fixedValue * 150 + barFrontPadding) + 'px';\n        actionElements[i].innerHTML = (actionResponse.weights[i]).toFixed(3);\n    }\n\n    if (actionResponse.wasRandom) {\n        randomActionValueElement.innerHTML = 'Infinity';\n        randomActionElement.style.width = (3 * 150 + barFrontPadding) + 'px';\n    } else {\n        randomActionValueElement.innerHTML = '0';\n        randomActionElement.style.width = '10px';\n    }\n}\n\nexport function renderReward(reward) {//@TODO move out\n    ensureElementsExist();\n    // reward *= 100;\n    let good = 0;\n    let bad = 0;\n    if (reward < 0) {\n        bad = -reward;\n    } else {\n        good = reward;\n    }\n\n    rewardElements[0].style.width = ((good + 1) * 200 + 100) + 'px';\n    rewardElements[0].innerHTML = good.toFixed(3);\n\n    rewardElements[1].style.width = ((bad + 1) * 200 + 100) + 'px';\n    rewardElements[1].innerHTML = bad.toFixed(3);\n}\n","import * as viewportConversions from '../environment/viewportConversions'\nimport { matrixToFlatArray } from '../environment/nestedFloatMatrixMath'\n// import { data as savedBrain } from '../../data/saves/tabular-sarsa'\nimport { Agent } from 'tabular-sarsa'\nimport { renderActionResponse, renderReward } from '../lib-agent-helper/qStateRenderer'\nimport { settings } from '../../App'\nimport { actions } from '../environment'\n\n/**\n * This controls whether we make the agent aware of what it's last action was. Setting this to true causes the agent\n * to get stuck in \"back and forth\" loops much less often but it also unfortunately makes it impossible to load saved\n * brain data in Chrome because chrome returns \"call stack size exceeded\" when parsing the large saved JSON.\n * @type {boolean}\n */\nconst rememberLastAction = true;\n\nconst viewportPixelCount = 5 * 3;\nexport const stateCount = Math.pow(2, viewportPixelCount) * (rememberLastAction ? actions.length : 1);\n\nvar agent = new Agent(stateCount, actions.length);\n\n// agent.loadFromJson(savedBrain);//Load the previously saved brain\n/**\n * Takes an array of 0s and 1s and converts the whole thing to a single int\n *\n * @param array\n * @returns {number}\n */\nexport function arrayOfBinariesToInt(array) {\n    var output = 0;\n    for (var i = 0, len = array.length; i < len; i++) {\n        output += array[i] * Math.pow(2, i);\n    }\n    return output;\n}\n\n/**\n * Take an observation object and returns an int that represents the given observation state\n *\n * @param {AgentObservation} observation\n * @param lastAction\n * @returns {number}\n */\nfunction observationToInt(observation, lastAction) {\n    var viewportState = arrayOfBinariesToInt(\n        matrixToFlatArray(\n            //Trim down the viewport to reduce the combinatorial explosion\n            viewportConversions.convert9x9to5x3(\n                observation\n            )\n        )\n    );\n    if (rememberLastAction) {\n        return viewportState * (lastAction + 1);\n    } else {\n        return viewportState;\n    }\n}\n\n\nexport default class TabularSARSA {\n    constructor() {\n        this._lastAction = 0;\n        // rewardCalculator = new RewardCalculator();\n    }\n\n    static getName() {\n        return 'ReinforcementLearning - TabularSARSA - 5x3 - ranked 224';\n    }\n\n    static getDescription() {\n        return 'This agent uses the Expected-SARSA algorithm with a table-based Q function.'\n            + ' The table stores the expected reward for ' + stateCount + ' possible states.'\n            + ' This agent views a 5x3 section of the viewport. '\n            + (rememberLastAction ? ' It also remembers the last action it took to help avoid loops.' : '');\n    }\n\n    /**\n     * @param {AgentObservation} observation\n     * @TODO clear last actions when is new game\n     * @return {string} action code\n     */\n    getAction(lastAction, lastReward, observationMatrix) {\n        // let reward = rewardCalculator.calcLastReward(observation);\n        var state = observationToInt(observationMatrix, this._lastAction);\n        var actionIndex = agent.decide(lastReward, state);\n        var lastActionStats = agent.getLastActionStats();\n        if (settings.renderingEnabled) {\n            renderActionResponse(\n                {\n                    weights: lastActionStats.weights,\n                    wasRandom: lastActionStats.wasRandomlyChosen\n                }\n            );\n            renderReward(lastReward);\n        }\n        this._lastAction = actionIndex;\n        return actionIndex;\n    }\n\n    newGame() { }\n\n    clearBrain() {\n        agent = new Agent(stateCount, actions.length);\n    }\n\n    exportBrain() {\n        return agent.saveToJson();\n    }\n}\n","export function getIndexOfMaxValue(array) {\n    var maxValue = array[0];\n    var maxIndex = 0;\n    for (var i = 1, length = array.length; i < length; i++) {\n        var v = array[i];\n        if (v > maxValue) {\n            maxIndex = i;\n            maxValue = v;\n        }\n    }\n    return maxIndex;\n}\n","import { matrixToFlatArray } from '../environment/nestedFloatMatrixMath'\nimport { settings } from '../../App' //@TODO use DI instead for this\nimport { renderActionResponse, renderReward } from '../lib-agent-helper/qStateRenderer'\nimport { actions, config } from '../environment'\nimport * as arrayMath from './math/arrayMath'\nimport { getRandomIntWithZeroMin } from './math/random'\nimport * as tf from '@tensorflow/tfjs';\n// tf.setBackend('cpu', true);//Increased actions per second from 34ish to 44ish in \"very fast\" view\nconst inputCount = config.viewPortSize[0] * config.viewPortSize[1];\nconst numberOfActions = actions.length;\nconst options = {};\nconst inputTensorShape = [1, 81];\n\nfunction createModel() {\n    const model = tf.sequential();\n    model.add(tf.layers.dense({inputShape: [81], units: 64, activation: 'relu' })); //@TODO make leaky?\n    model.add(tf.layers.dense({ units: 4, activation: 'linear' }));\n    model.compile({\n        optimizer: 'adam',\n        loss: 'meanSquaredError'\n    });\n    return model\n}\n\nexport default class DeepQNetworkTensorFlow {\n    constructor() {\n        this.learnFromOARO = this.learnFromOARO.bind(this)\n        var defaultOptions = {\n            discountFactor: 0.9, //was .075, future reward discount factor\n            explorationProbability: 0.05\n        };\n\n        this.options = Object.assign(defaultOptions, options);\n\n        this.model = createModel();\n\n        this.numberOfInputs = inputCount;\n        this.numberOfActions = numberOfActions;\n\n        this.learnAndActCallCount = 0;\n\n        this.connectingObservation = null;\n        this.lastOAR = {\n            observation: null,\n            action: null,\n            reward: null\n        }\n\n        // this.recentOAROs = [];\n    }\n\n    static getName() {\n        return 'ReinforcementLearning - DeepQNetworkTensorFlow - 9x9 - untrained'\n    }\n\n    /**\n     *\n     * @param {AgentObservation} observation\n     * @return {int} action index\n     */\n    getAction(lastAction, lastReward, observationMatrix) {\n        const observation = matrixToFlatArray(observationMatrix);\n\n        this.lastOAR = {\n            observation: this.connectingObservation,\n            action: lastAction,\n            reward: lastReward\n        };\n        this.connectingObservation = observation;\n\n        // this.recentOAROs.push([this.lastOAR.observation, this.lastOAR.action, this.lastOAR.reward, observation]);\n        // if (this.recentOAROs.length > 10) {\n        //     this.recentOAROs.map((example) => {\n        //         if (example[0] !== null && example[1] !== null && example[2] !== null && example[3] !== null) {\n        //             this.learnFromOARO(example[0], example[1], example[2], example[3]);\n        //         }\n        //     });\n        //     this.recentOAROs = [];\n        // }\n        if (this.lastOAR.observation !== null) {\n            this.learnFromOARO(this.lastOAR.observation, this.lastOAR.action, this.lastOAR.reward, observation);\n        }\n\n        let actionWasRandom = false;\n        let actionWeights = null;\n        let action;\n\n        //epsilon greedy policy\n        if (Math.random() < this.options.explorationProbability) {\n            action = getRandomIntWithZeroMin(this.numberOfActions);\n            actionWasRandom = true;\n            actionWeights = [0, 0, 0, 0];//@TODO don't hard code action count\n        } else {\n            // greedy wrt Q function\n            var actionMatrix = this.modelPredict(observation);\n            actionWeights = actionMatrix;\n            action = arrayMath.getIndexOfMaxValue(actionMatrix); // returns index of argmax action\n        }\n\n        if (settings.renderingEnabled) {\n            renderActionResponse({\n                action: action,\n                wasRandom: actionWasRandom,\n                weights: actionWeights\n            });\n            if (lastReward !== null) {\n                renderReward(lastReward)\n            }\n        }\n\n        return action;\n    }\n\n    newGame() {\n        this.connectingObservation = null;\n        this.lastOAR = {\n            observation: null,\n            action: null,\n            reward: null\n        }\n    }\n\n    modelPredict(observationArray) {\n        return tf.tidy(() => {\n            const observationTensor = tf.tensor(observationArray, inputTensorShape);\n            const predictedRewardsByActionTensor = this.model.predictOnBatch(observationTensor);\n            const predictedRewardsByActionArray = predictedRewardsByActionTensor.dataSync();\n            return predictedRewardsByActionArray;\n        });\n    }\n\n    modelTrain(observationArray, targetDataArray) {\n        const observationTensor = tf.tensor(observationArray, inputTensorShape);\n        const targetTensor = tf.tensor(targetDataArray, [1, this.numberOfActions]);\n        this.model.trainOnBatch(observationTensor, targetTensor).then((trainOnBatchResult) => {\n            observationTensor.dispose();\n            targetTensor.dispose();\n        });\n    }\n\n    learnFromOARO(lastObservation, lastAction, lastReward, currentObservation) {\n        const estimatedFutureReward = this.estimateNextActionReward(currentObservation);\n        const target = this.modelPredict(lastObservation);\n        const targetActionValue = lastReward + estimatedFutureReward * this.options.discountFactor;\n        target[lastAction] = targetActionValue;\n        this.modelTrain(lastObservation, target);\n    }\n\n    estimateNextActionReward(currentObservation) {\n        const predictedRewardByAction = this.modelPredict(currentObservation);\n        const rewardIfDontExplore = predictedRewardByAction[arrayMath.getIndexOfMaxValue(predictedRewardByAction)];\n        const rewardIfExplore = predictedRewardByAction.reduce(\n            (accumulator, currentValue) => {\n                return accumulator + currentValue / this.numberOfActions\n            }\n        );\n        return rewardIfDontExplore * (1 - this.options.explorationProbability)\n            + rewardIfExplore * this.options.explorationProbability;\n    }\n\n    clearBrain() {\n        alert('not implemented')\n    }\n\n    exportBrain() {\n        alert('not implemented')\n    }\n}\n","export function getRandomIntWithZeroMin(max) {\n    return Math.floor(Math.random() * max);\n}\n","import LookAhead9x3 from './modules/agent-hand-programmed-look-ahead/LookAhead9x3'\n// import DeepQNetwork from './modules/agent-deep-q-scratch-built/DeepQNetwork'\nimport TabularSARSA from './modules/agent-tabular-sarsa/TabularSARSA'\nimport DeepQNetworkTensorFlow from './modules/agent-deep-q-network-tensor-flow'\nexport default [\n    {\n        name: DeepQNetworkTensorFlow.getName(),\n        class: DeepQNetworkTensorFlow\n    },\n    // {\n    //     name: DeepQNetwork.getName(),\n    //     class: DeepQNetwork\n    // },\n    {\n        class: TabularSARSA,\n        name: TabularSARSA.getName(),\n        description: TabularSARSA.getDescription(),\n        ticksPerInterval: 20000 //This agent runs fast but needs many games to learn\n    },\n    {\n        name: LookAhead9x3.getName(),\n        class: LookAhead9x3\n    },\n];\n","import { default as Environment, actions,config } from './modules/environment'\nconst historyLength = 1000;\n\nconst defaultStats = {\n    currentScore: 0,\n    lastGameScore: 0,\n    scoreSum: 0,\n    gameCount: 0,\n    actionCount: 0,\n    actionsPerSecond: 0,\n    lastSecondsActionCount: 0,\n    lastFinalScores: [],\n    gameCountToScore: [],\n    gameCountToAverageScore: [],\n    averageFinalScore: 0,\n    lastActionScore: 0,\n    totalReward: 0,\n};\n\nexport default class GameRunner {\n    constructor(onRender, onStatusChange) {\n        this._universalGameNumber = 0;\n        this._renderingEnabled = false;\n        this._onRender = onRender;\n        this._stats = Object.assign({}, defaultStats);\n        this._onStatusChange = onStatusChange;\n        this._agentObservation = null;\n        this._godObservation = null;\n        // this._agentClass = null;\n        // this._nextAction = null;\n        this._nextAction = 0;//@TODO this doesn't seem right\n\n        this.newGame = this.newGame.bind(this);\n        this.takeAction = this.takeAction.bind(this);\n        this.tick = this.tick.bind(this);\n        this.clearStats = this.clearStats.bind(this);\n        this.setRenderingEnabled = this.setRenderingEnabled.bind(this);\n\n        this.last = { action: null, reward: null };\n\n        setInterval(() => {//@TODO accomplish this without an interval\n            this._stats.actionsPerSecond = this._stats.actionCount - this._stats.lastSecondsActionCount;\n            this._stats.lastSecondsActionCount = this._stats.actionCount;\n        }, 1000);\n    }\n\n    newGame(agentInstance) {\n        this._universalGameNumber++;\n        // this._agentClass = agentClass;\n        this._agent = agentInstance;\n        // this._agent = new this._agentClass();\n        // this._renderingEnabled = renderingEnabled;\n        this._environment = new Environment();\n        this._stats.currentScore = 0;//@TODO get from environment?\n        if (this._renderingEnabled) {\n            //@TODO have this render make the table its self inside a given div\n            // this._onRender.clear();\n            this._onRender(\n                this._environment.getAgentObservation(),\n                this._environment.getGodObservation(),\n                this._universalGameNumber\n            );\n        } else {\n            this._onStatusChange(this._stats);\n        }\n        this._updateObservations();\n    }\n\n    clearCurrentAgentBrain() {\n        if (this._agent.clearBrain) {\n            this._agent.clearBrain();\n        }\n    }\n\n    /**\n     *\n     * @param actionCode\n     */\n    takeAction(action) {\n        var stats = this._stats;\n        const actionCode = actions[action];\n        //Apply the action and get the next observation\n        if (actionCode !== null) {\n            this._environment.applyAction(actionCode);\n        }\n        this._updateObservations();\n\n        if (this._godObservation.isComplete) {//@Find better way to communicate \"isComplete\"\n            this._agent.getAction(this.last.action, this.last.reward, this._agentObservation.tileTypes);//Ask for one more action so the agent can see the observation after its last action\n            this._agent.newGame();\n            stats.lastGameScore = this._agentObservation.score;\n            stats.lastFinalScores.push(this._agentObservation.score);\n            if (stats.lastFinalScores.length > 100) {\n                stats.lastFinalScores.shift();\n            }\n            var totalScoreFinaleScore = stats.lastFinalScores.reduce((acc, val) => acc + val, 0);\n            stats.averageFinalScore = (totalScoreFinaleScore / stats.lastFinalScores.length) || 0;\n            stats.scoreSum += this._agentObservation.score;\n            stats.gameCountToScore.push(stats.lastGameScore);\n            stats.gameCountToAverageScore.push(stats.averageFinalScore);\n            stats.gameCount += 1;\n\n            //If the history arrays get twice as large as the preferred history length, slice them off.\n            if (stats.gameCountToScore.length > historyLength * 2) {\n                stats.gameCountToScore = stats.gameCountToScore.slice(-historyLength);\n                stats.gameCountToAverageScore = stats.gameCountToAverageScore.slice(-historyLength);\n            }\n\n            this.newGame(this._agent, this._renderingEnabled);\n        }\n\n        if (this._renderingEnabled) {\n            this._onRender(this._agentObservation, this._godObservation, this._universalGameNumber);\n            stats.currentScore = this._agentObservation.score;\n            this._onStatusChange(stats);\n        }\n\n        stats.actionCount++;\n        var reward = this._agentObservation.score - stats.lastActionScore;\n        stats.lastActionScore = this._agentObservation.score;\n        stats.totalReward += reward;\n\n        this.last.reward = reward;\n        this.last.action = action;\n\n        this._nextAction = this._agent.getAction(this.last.action, this.last.reward, this._agentObservation.tileTypes);\n    }\n\n    setRenderingEnabled(renderingEnabled) {\n        this._renderingEnabled = renderingEnabled;\n    }\n\n    getCurrentAgentInstance() {\n        return this._agent;\n    }\n\n    tick() {\n        this.takeAction(this._nextAction);\n    }\n\n    clearStats() {\n        this._stats = Object.assign({}, defaultStats);\n        this._stats.lastFinalScores = [];\n        this._stats.gameCountToScore = [];\n        this._stats.gameCountToAverageScore = [];\n    }\n\n    _updateObservations() {\n        this._agentObservation = this._environment.getAgentObservation();\n        this._godObservation = this._environment.getGodObservation();\n    }\n}\n","import React, {Component} from 'react';\nimport PropTypes from 'prop-types'\n\nexport default class StatsDisplay extends Component {\n    render() {\n        const stats = this.props.stats;\n        return (\n            <table>\n                <tbody>\n                {Object.keys(stats).map((key) =>\n                    <tr key={key}>\n                        <td>{key}: {stats[key]}</td>\n                    </tr>\n                )}\n                </tbody>\n            </table>\n        );\n    }\n}\n\nStatsDisplay.propTypes = {\n    stats: PropTypes.object.isRequired\n};\n\n","import './App.css';\nimport React, { Component } from 'react';\nimport { config as environmentConfig, actions } from './modules/environment'\nimport ObservationRenderer from './modules/react-ui-component/ObservationRenderer'\nimport BrainExportButton from './modules/react-ui-component/BrainExportButton'\nimport ScoreHistoryChart from './modules/react-ui-component/ScoreHistoryChart'\nimport GameRulesDisplay from './modules/react-ui-component/GameRulesDisplay'\nimport agents from './agents'\nimport GameRunner from './GameRunner'\nimport StatsDisplay from './modules/react-ui-component/StatsDisplay'\n\nexport const settings = {//@TODO move out of global?\n    // renderingEnabled: false,\n    // speed: 10000000000,\n    renderingEnabled: true,\n    speed: 250,//250,\n    ticksPerIntervalWhenNotRendering: 100, //100 is good for speed, 10 is good for precise \"actions per second\" readout\n    autoPlay: true,\n};\n\nexport default class App extends Component {\n    constructor() {\n        super();\n        this.setupInterval = this.setupInterval.bind(this);\n        this.handleGameRunnerStatusChange = this.handleGameRunnerStatusChange.bind(this);\n        this.handleSpeedSelectorChange = this.handleSpeedSelectorChange.bind(this);\n        this.handleGameRendererRender = this.handleGameRendererRender.bind(this);\n        this.handleAgentSelectorChange = this.handleAgentSelectorChange.bind(this);\n        this.handleClearBrainClick = this.handleClearBrainClick.bind(this);\n        this.handleManualControlKeyDown = this.handleManualControlKeyDown.bind(this);\n        this.handleManualControlClick = this.handleManualControlClick.bind(this);\n\n        this._agents = agents;//@TODO take as construct arg?\n        this.agentInstances = [];\n\n        this._settings = settings;//@TODO take as construct arg?\n\n        this.state = {\n            statsToDisplay: {},\n            agentObservation: null,\n            godObservation: null,\n            universalGameNumber: 0,\n            currentAgentIndex: 0,\n            speed: this._settings.speed,\n            lastStatusRenderTime: 0,\n            lastStatusChartRenderTime: 0,\n            scoreHistoryChartData: null\n        };\n\n    }\n\n    componentWillMount() {\n        this._gameRunner = new GameRunner(this.handleGameRendererRender, this.handleGameRunnerStatusChange);\n\n        this.clearStatsAndNewGame();\n        this.setupInterval();\n    }\n\n    handleGameRendererRender(agentObservation, godObservation, universalGameNumber) {\n        this.setState({\n            agentObservation: agentObservation,\n            godObservation: godObservation,\n            universalGameNumber: universalGameNumber\n        })\n    }\n\n    handleGameRunnerStatusChange(stats) {\n        var nowMilliseconds = (new Date()).getTime();\n        if (nowMilliseconds > this.state.lastStatusRenderTime + 250) {//Refuse to render status html faster than 4fps\n            this.setState({\n                statsToDisplay: {\n                    // 'Agent' :currentAgentName ,\n                    'Current Score': stats.currentScore.toFixed(3),\n                    'Actions per second': stats.actionsPerSecond.toLocaleString(),\n                    'Last Game Final Score': stats.lastGameScore.toFixed(3),\n                    'Average Final Score (trailing)': stats.averageFinalScore.toFixed(3),\n                    'Average Final Score (all time)': ((stats.scoreSum / stats.gameCount) || 0).toFixed(3),\n                    // 'Average Reward' : (stats.totalReward / stats.actionCount).toFixed(2) ,\n                    'Game Count': stats.gameCount.toLocaleString()\n                },\n                lastStatusRenderTime: nowMilliseconds\n            });\n        }\n\n        if (nowMilliseconds > this.state.lastStatusChartRenderTime + 50) {//Refuse to render status chart faster than 20fps\n\n            if (settings.renderingEnabled) {//Don't draw chart if rendering games\n                return;\n            }\n\n            this.setState({\n                scoreHistoryChartData: stats,\n                lastStatusChartRenderTime: nowMilliseconds\n            });\n        }\n\n    }\n\n    setupInterval() {\n        var self = this;\n        clearInterval(this._intervalReference);\n        if (this._settings.autoPlay) {\n            var ticksPerInterval = this._settings.ticksPerIntervalWhenNotRendering;\n            if (this._agents[this.state.currentAgentIndex].ticksPerInterval) {\n                //Allow very fast or very slow agents to have their own setting\n                ticksPerInterval = this._agents[this.state.currentAgentIndex].ticksPerInterval;\n            }\n            if (this._settings.renderingEnabled) {\n                ticksPerInterval = 1\n            }\n            //Normal ticking takes 3ms between ticks which is not fast enough, so tick 100 times\n            this._intervalReference = setInterval(function () {\n                for (let i = 0; i < ticksPerInterval; i++) {\n                    self._gameRunner.tick();\n                }\n            }, this._settings.speed);\n        }\n    }\n\n    clearStatsAndNewGame() {\n        this._gameRunner.setRenderingEnabled(this._settings.renderingEnabled);\n        this._gameRunner.clearStats();\n        if (!this.agentInstances[this.state.currentAgentIndex]) {\n            this.agentInstances[this.state.currentAgentIndex] = new this._agents[this.state.currentAgentIndex].class();\n        }\n        this._gameRunner.newGame(this.agentInstances[this.state.currentAgentIndex], this._settings.renderingEnabled);\n    }\n\n    setSpeed(value) {//@TODO use setState in here\n        this.setState({ speed: value });\n        let newEnableRenderingValue = true;\n        this._settings.autoPlay = true;\n        if (value === 'no-render') {\n            newEnableRenderingValue = false;\n            this._settings.speed = 0;\n        } else if (value === 'paused') {\n            this._settings.autoPlay = false;\n        } else {\n            this._settings.speed = value;\n        }\n        if (newEnableRenderingValue !== this._settings.renderingEnabled) {\n            this._settings.renderingEnabled = newEnableRenderingValue;\n            this._gameRunner.setRenderingEnabled(this._settings.renderingEnabled);\n        }\n        this.setupInterval();\n    }\n\n    handleSpeedSelectorChange(event) {\n        this.setSpeed(event.target.value);\n\n    }\n\n    componentDidUpdate(prevProps, prevState) {\n        if (prevState.currentAgentIndex !== this.state.currentAgentIndex) {\n            //Is the agent was changed, clear stats and start a new game\n            this.clearStatsAndNewGame();\n            this.setupInterval();//Some agents have their own speed interval so re setup the interval\n        }\n    }\n\n    handleAgentSelectorChange(event) {\n        this.setState({ currentAgentIndex: event.target.value });\n    }\n\n    handleClearBrainClick() {\n        this._gameRunner.clearCurrentAgentBrain();\n        this.clearStatsAndNewGame();\n    }\n\n    handleManualControlKeyDown(event) {\n        const action = actions.indexOf(event.key);\n        if (action !== -1) {\n            this._gameRunner.takeAction(action);\n        }\n    }\n\n    handleManualControlClick() {\n        this.setSpeed('paused');\n    }\n\n    render() {\n        return (\n            <div>\n                <div id=\"info\">Agent:\n                    <select onChange={this.handleAgentSelectorChange}>\n                        {this._agents.map(((agent, index) =>\n                            <option key={index} value={index}>{agent.name}</option>\n                        ))\n                        }\n                    </select>\n                    &nbsp;\n                    <button onClick={this.handleClearBrainClick}>Clear Brain and Retrain</button>\n                    <br />\n                    Speed:\n                    <select onChange={this.handleSpeedSelectorChange} value={this.state.speed}>\n                        <option value=\"no-render\">Ludicrous Speed (no rendering)</option>\n                        <option value=\"0\">Very Fast</option>\n                        <option value=\"100\">Fast</option>\n                        <option value=\"250\">Medium</option>\n                        <option value=\"500\">Slow</option>\n                        <option value=\"paused\">Paused</option>\n                    </select>\n                    &nbsp;\n                    <button type=\"text\"\n                        onKeyDown={this.handleManualControlKeyDown}\n                        onClick={this.handleManualControlClick}>Enable Manual Control (WASD)\n                    </button>\n                    <pre id=\"score\" />\n                    <StatsDisplay stats={this.state.statsToDisplay} />\n                    <br />\n                </div>\n                {!this._settings.renderingEnabled && this.state.scoreHistoryChartData &&\n                    <div style={{ width: '30em' }}>\n                        <ScoreHistoryChart stats={this.state.scoreHistoryChartData} />\n                    </div>\n                }\n                {this._settings.renderingEnabled && this.state.agentObservation &&\n                    <div>\n                        <ObservationRenderer\n                            agentObservation={this.state.agentObservation}\n                            godObservation={this.state.godObservation}\n                            gameNumber={this.state.universalGameNumber}\n                        />\n                        <div id=\"agentRendererContainer\"></div>\n                        {this._agents[this.state.currentAgentIndex].description &&\n                            <div>\n                                {this._agents[this.state.currentAgentIndex].description}\n                            </div>\n                        }\n                    </div>\n                }\n                <br />\n                <GameRulesDisplay environmentConfig={environmentConfig} />\n                <br />\n                <BrainExportButton gameRunner={this._gameRunner} />\n            </div>\n        );\n    }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\nimport './index.css';\n\nReactDOM.render(\n  <App />,\n  document.getElementById('root')\n);\n\n\n\n//import './modules/deep-q-network/neural-network/networkTest'\n"],"sourceRoot":""}